{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 11 Search Trees\n",
    "## 11.1 Binary Search Trees\n",
    "이번 챕터에서는 트리를 이용해서 **sorted map**을 구현하는 법을 알아보자. **이진 탐색 트리(binary search tree)**는 key에 순서가 잘 정의된다고 가정하면 맵의 항목들을 저장하기에 매우 효율적인 자료 구조이다. 이진 탐색 트리는 key-value 페어 (k,v)를 저장하고 있는 위치 $p$에 대해 다음의 두 성질을 만족하는 이진 트리이다:\n",
    "\n",
    "- $p$의 왼쪽 서브트리에 저장된 key는 $k$보다 작다.\n",
    "- $p$의 오른쪽 서브트리에 저장된 key는 $k$보다 크다.\n",
    "\n",
    "<img width=\"400\" alt=\"figure-11.1\" src=\"https://user-images.githubusercontent.com/20944657/37070697-232fd688-21fc-11e8-84c6-091b490c38f9.png\">\n",
    "\n",
    "### 11.1.1 Navigating a Binary Search Tree\n",
    "**Proposition 11.1:** 이진 탐색 트리의 중위 운행법은 key의 오름차순대로 위치들을 방문하게 된다.\n",
    "\n",
    "**Justification:** 귀납법을 이용하면 쉽게 보일 수 있다. 생략한다.\n",
    "\n",
    "이진 탐색 트리는 이진 트리 ADT가 지원하는 `parent(p)`, `left(p)`, `right(p)`와 같은 메소드 외에도 트리 내에 저장된 키의 자연스러운 순서에 따라 트리를 탐색하는 다음의 메소드들을 지원한다\n",
    "\n",
    "- **first():** 최소 키를 가진 위치를 반환한다. 트리가 비어있다면 None을 반환한다.\n",
    "- **last():** 최대 키를 가진 위치를 반환한다. 트리가 비어있다면 None을 반환한다.\n",
    "- **before(p):** $p$의 키보다 작으면서 가장 큰 키를 가진 위치를 반환한다(i.e. 중위 운행법에서 $p$를 방문하기 직전에 방문한 위치). $p$가 첫번째 위치라면 None을 반환한다.\n",
    "- **after(p):** $p$의 키보다 크면서 가장 작은 키를 가진 위치를 반환한다(i.e. 중위 운행법에서 $p$를 방문한 후에 방문하는 위치).\n",
    "\n",
    "이 중 `after(p)`는 다음의 알고리즘을 통해 구현할 수 있다. \n",
    "\n",
    "**Algorithm** after(p):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**if** right(p) is not None **then**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;walk = right(p)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**while** left(walk) is not None **do**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;walk = left(walk)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**return** walk<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**else**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;walk = p<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ancestor = parent(walk)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**while** ancestor is not None and walk == right(ancester) do<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;walk = ancestor<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ancestor = parent(walk)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**return** ancestor<br>\n",
    "\n",
    "다른 메소드도 비슷한 알고리즘을 통해 구현할 수 있다. 이 때 `after(p)`나 `before(p)`의 최악의 작동 시간은 $O(h)$가 될 것이지만, $n$번의 연속적인 `after(p)`나 `before(p)`가 $O(n)$ 시간복잡도를 가질 것이라는 점을 고려하면 각각은 **amortized** $O(1)$ 시간이 걸린다.\n",
    "\n",
    "### 11.1.2 Searches\n",
    "<img style=\"float: left\" width=\"400\" alt=\"figure-11.2a\" src=\"https://user-images.githubusercontent.com/20944657/37071041-f77c9268-21fd-11e8-8ce7-e58a7789b384.png\">\n",
    "<img style=\"float: left\" width=\"400\" alt=\"figure-11.2b\" src=\"https://user-images.githubusercontent.com/20944657/37071047-fd449b1e-21fd-11e8-8bb2-c033384e144c.png\">\n",
    "<div style=\"clear: both\"></div>\n",
    "\n",
    "위의 첫번째 그림은 이진 탐색 트리에서 65를 성공적으로 찾은 사례이고, 두번째 그림은 이진 탐색 트리에서 68을 탐색하는 데 실패한 사례이다. 탐색 알고리즘은 다음과 같다.\n",
    "\n",
    "**Algorithm** TreeSearch(T, p, k):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**if** k == p.key() **then**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**return** p<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**else if** k < p.key() and T.left(p) is not None **then**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**return** TreeSearch(T, T.left(p), k)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**else if** k > p.key() and T.right(p) is not None **then**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**return** TreeSearch(T, T.right(p), k)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**return** p<br>\n",
    "\n",
    "### Analysis of Binary Tree Searching\n",
    "`TreeSearch` 알고리즘은 재귀적이어서 매번 호출될때마다 상수 시간의 작업을 한다. 그러면 탐색의 시간 복잡도가 $O(h)$일 것임은 아래의 그림에서와 같이 쉽게 알 수 있다. 이 때 $h$는 최대 $n$이 될 수도 있지만, 이 챕터의 후반부에서 탐색 트리의 높이를 $O(logn)$으로 유지하기 위한 여러 전략을 소개할 것이다\n",
    "\n",
    "<img width=\"500\" alt=\"figure-11.3\" src=\"https://user-images.githubusercontent.com/20944657/37071335-63d0bbfa-21ff-11e8-87f9-a8497d2a1c93.png\">\n",
    "\n",
    "### 11.1.3 Insertions and Deletions\n",
    "### Insertion\n",
    "항목의 추가를 위한 알고리즘은 다음과 같다.\n",
    "\n",
    "**Algorithm** TreeInsert(T, k, v):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Input:** A search key k to be associated with value v<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;p = TreeSearch(T, T.root(), k)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**if** k == p.key() **then**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Set p's value to v<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**else if** k < p.key() **then**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;add node with item (k,v) as left child of p<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**else**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;add node with item (k,v) as right child of p<br>\n",
    "\n",
    "<img style=\"float: left\" width=\"400\" alt=\"figure-11.4a\" src=\"https://user-images.githubusercontent.com/20944657/37071449-eef4e864-21ff-11e8-808b-a2d1b1b9483d.png\">\n",
    "<img style=\"float: left\" width=\"400\" alt=\"figure-11.4b\" src=\"https://user-images.githubusercontent.com/20944657/37071455-f409bcc6-21ff-11e8-8b46-a4f8c13cae0c.png\">\n",
    "<div style=\"clear: both\"></div>\n",
    "\n",
    "위 그림의 첫번째 그림은 key 68을 추가할 위치를 찾는 과정이고, 두번째 그림은 key 68을 추가한 후의 그림이다.\n",
    "\n",
    "### Deletion\n",
    "`p = TreeSearch(T, T.root(), k)`를 통해 삭제할 위치 $p$를 찾는다. 만약 $p$의 자식이 없다면 그냥 지우면 되고, $p$의 자식이 하나라면 $p$를 지우고, $p$의 부모와 $p$의 자식을 연결하면 된다. $p$의 자식이 둘이면 좀 더 복잡한데, $p$보다 작은 key 중에서 가장 큰 key를 저장하는 위치 $r$을 찾는다. $p$가 자식이 둘이므로 `before(p)`를 통해 $r$을 찾으면 $r$은 $p$의 왼쪽 서브트리에서 가장 오른쪽에 있는 위치일 것이다. 이제 $p$를 지우는 대신 $p$의 내용물을 $r$의 항목으로 교체하고, $r$을 지운다. $r$은 가장 오른쪽에 있는 위치이므로 자식이 없기 때문에 쉽게 지울 수 있다.\n",
    "\n",
    "<img style=\"float: left\" width=\"400\" alt=\"figure-11.4a\" src=\"https://user-images.githubusercontent.com/20944657/37071602-99fa119e-2200-11e8-85ee-885ae474e874.png\">\n",
    "<img style=\"float: left\" width=\"400\" alt=\"figure-11.4b\" src=\"https://user-images.githubusercontent.com/20944657/37071603-9a25677c-2200-11e8-8a1b-68eab846de8f.png\">\n",
    "<div style=\"clear: both\"></div>\n",
    "\n",
    "위의 그림은 key 32를 지우려고 할 때 $p$가 하나의 자식 $r$을 가질 때의 예제이고, 아래의 그림은 key 88을 지우려고 할 때 $p$가 두 자식을 가질 때의 예제이다.\n",
    "\n",
    "<img style=\"float: left\" width=\"400\" alt=\"figure-11.4a\" src=\"https://user-images.githubusercontent.com/20944657/37071604-9a50e140-2200-11e8-9d27-8993bb3ebae4.png\">\n",
    "<img style=\"float: left\" width=\"400\" alt=\"figure-11.4b\" src=\"https://user-images.githubusercontent.com/20944657/37071605-9a85fda8-2200-11e8-824e-8360900647e0.png\">\n",
    "<div style=\"clear: both\"></div>\n",
    "\n",
    "### 11.1.4 Python Implementation\n",
    "이제 파이썬 코드로 이진 탐색 트리를 어떻게 구현할 수 있는지 알아보자. 아래의 코드에서 주목할 부분은 **다중 상속(multiple inheritance)**을 이용한 부분과, 이후 탐색 트리의 밸런싱을 할 때 사용할 수 있게끔 `_rebalance_insert_`, `_rebalance_delete`, `_rebalance_access` 메소드를 **훅** 으로 정의한 부분이다. 이는 Section 11.2에서 다룰 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TreeMap(LinkedBinaryTree, MapBase):\n",
    "    \"\"\"Sorted map implementation using a binary search tree.\"\"\"\n",
    "    \n",
    "    #--------------------- override Position class ---------------------------\n",
    "    class Position(LinkedBinaryTree.Position):\n",
    "        def key(self):\n",
    "            \"\"\"Return key of map's key-value pair.\"\"\"\n",
    "            return self.element()._key\n",
    "        \n",
    "        def value(self):\n",
    "            \"\"\"Return value of map's key-value pair.\"\"\"\n",
    "            return self.element()._value\n",
    "        \n",
    "    #--------------------- nonpublic utilities -------------------------------\n",
    "    def _subtree_search(self, p, k):\n",
    "        \"\"\"Return Position of p's subtree having key k, or last node searched.\"\"\"\n",
    "        if k == p.key():                                        # found match\n",
    "            return p\n",
    "        elif k < p.key():                                       # search left subtree\n",
    "            if self.left(p) is not None:\n",
    "                return self._subtree_search(self.left(p), k)\n",
    "        else:                                                   # search right subtree\n",
    "            if self.right(p) is not None:\n",
    "                return self._subtree_search(self.right(p), k)\n",
    "        return p                                                # unsuccessful search\n",
    "    \n",
    "    def _subtree_first_position(self, p):\n",
    "        \"\"\"Return Position of first item in subtree rooted at p.\"\"\"\n",
    "        walk = p\n",
    "        while self.left(walk) is not None:                      # keep walking left\n",
    "            walk = self.left(walk)\n",
    "        return walk\n",
    "    \n",
    "    def _subtree_last_position(self, p):\n",
    "        \"\"\"Return Position of last item in subtree rooted at p.\"\"\"\n",
    "        walk = p\n",
    "        while self.right(walk) is not None:                     # keep walking right\n",
    "            walk = self.right(walk)\n",
    "        return walk\n",
    "    \n",
    "    def first(self):\n",
    "        \"\"\"Return the first Position in the tree (or None if empty).\"\"\"\n",
    "        return self._subtree_first_position(self.root()) if len(self) > 0 else None\n",
    "    \n",
    "    def last(self):\n",
    "        \"\"\"Return the last Position in the tree (or None if empty).\"\"\"\n",
    "        return self._subtree_last_position(self.root()) if len(self) > 0 else None\n",
    "    \n",
    "    def before(self, p):\n",
    "        \"\"\"Return the Position just before p in the natural order.\n",
    "        \n",
    "        Return None if p is the first position.\n",
    "        \"\"\"\n",
    "        self._validate(p)\n",
    "        if self.left(p):\n",
    "            return self._subtree_last_position(self.left(p))\n",
    "        else:\n",
    "            # walk upward\n",
    "            walk = p\n",
    "            above = self.parent(walk)\n",
    "            while above is not None and walk == self.left(above):\n",
    "                walk = above\n",
    "                above = self.parent(walk)\n",
    "            return above\n",
    "        \n",
    "    def after(self, p):\n",
    "        \"\"\"Return the Position just after p in the natural order.\n",
    "        \n",
    "        Return None if p is the last position.\n",
    "        \"\"\"\n",
    "        self._validate(p)\n",
    "        if self.right(p):\n",
    "            return self._subtree_first_position(self.right(p))\n",
    "        else:\n",
    "            #walk upward\n",
    "            walk = p\n",
    "            above = self.parent(walk)\n",
    "            while above is not None and walk == self.right(above):\n",
    "                walk = above\n",
    "                above = self.parent(walk)\n",
    "            return above\n",
    "        \n",
    "    def find_position(self, k):\n",
    "        \"\"\"Return position with key k, or else neighbor (or None if empty.)\"\"\"\n",
    "        if self.is_empty():\n",
    "            return None\n",
    "        else:\n",
    "            p = self._subtree_search(self.root(), k)\n",
    "            self._rebalance_access(p)              # hook for balanced tree subclasses\n",
    "            return p\n",
    "        \n",
    "    def find_min(self):\n",
    "        \"\"\"Return (key, value) pair with minimum key (or None if empty).\"\"\"\n",
    "        if self.is_empty():\n",
    "            return None\n",
    "        else:\n",
    "            p = self.first()\n",
    "            return (p.key(), p.value())\n",
    "        \n",
    "    def find_ge(self, k):\n",
    "        \"\"\"Return (key, value) pair with least key greater than or equal to k.\n",
    "        \n",
    "        Return None if there does not exist such a key.\n",
    "        \"\"\"\n",
    "        if self.is_empty():\n",
    "            return None\n",
    "        else:\n",
    "            p = self.find_position(k)\n",
    "            if p.key() < k:\n",
    "                p = self.after(p)\n",
    "            return (p.key(), p.value()) if p is not None else None\n",
    "        \n",
    "    def find_range(self, start, stop):\n",
    "        \"\"\"Iterate all (key, value) pairs such that start <= key < stop.\n",
    "        \n",
    "        If start is None, iteration begins with minimum key of map.\n",
    "        If stop is None, iterations continues through the maximum key of map.\n",
    "        \"\"\"\n",
    "        if not self.is_empty():\n",
    "            if start is None:\n",
    "                p = self.first()\n",
    "            else:\n",
    "                # we initialize p with logic similar to find_ge\n",
    "                p = self.find_position(start)\n",
    "                if p.key() < start:\n",
    "                    p = self.after(p)\n",
    "            while p is not None and (stop is None or p.key() < stop):\n",
    "                yield (p.key(), p.value())\n",
    "                p = self.after(p)\n",
    "                \n",
    "    def __getitem__(self, k):\n",
    "        \"\"\"Return value associated with key k (raise KeyError if not found).\"\"\"\n",
    "        if self.is_empty():\n",
    "            raise KeyError('Key Error: ' + repr(k))\n",
    "        else:\n",
    "            p = self._subtree_search(self.root(), k)\n",
    "            self._rebalance_access(p)              # hook for balanced tree subclasses\n",
    "            if k != p.key():\n",
    "                raise KeyError('Key Error: ' + repr(k))\n",
    "            return p.value()\n",
    "        \n",
    "    def __setitem__(self, k, v):\n",
    "        \"\"\"Assign value v to key k, overwriting existing value if present.\"\"\"\n",
    "        if self.is_empty():\n",
    "            leaf = self._add_root(self._Item(k,v))             # from LinkedBinaryTree\n",
    "        else:\n",
    "            p = self._subtree_search(self.root(), k)\n",
    "            if p.key() == k:\n",
    "                p.element()._value = v                         # replace existing item's value\n",
    "                self._rebalance_access(p)                      # hook for balanced tree subclasses\n",
    "                return\n",
    "            else:\n",
    "                item = self._Item(k,v)\n",
    "                if p.key() < k:\n",
    "                    leaf = self._add_right(p, item)            # inherited from LinkedBinaryTree\n",
    "                else:\n",
    "                    leaf = self._add_left(p, item)             # inherited from LinkedBinaryTree\n",
    "        self._rebalance_insert(leaf)                           # hook for balanced tree subclasses\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Generate an iteration of all keys in the map in order.\"\"\"\n",
    "        p = self.first()\n",
    "        while p is not None:\n",
    "            yield p.key()\n",
    "            p = self.after(p)\n",
    "            \n",
    "    def delete(self, p):\n",
    "        \"\"\"Remove the item at given Position.\"\"\"\n",
    "        self._validate(p)                                 # inherited from LinkedBinaryTree\n",
    "        if self.left(p) and self.right(p):                # p has two children\n",
    "            replacement = self._subtree_last_position(self.left(p))\n",
    "            self._replace(p, replacement.element())       # from Linked Binary Tree\n",
    "            p = replacement\n",
    "        # now p has at most one child\n",
    "        parent = self.parent(p)\n",
    "        self._delete(p)                                   # inherited from Linked Biary Tree\n",
    "        self._rebalance_delete(parent)                    # if root deleted, parent is None\n",
    "        \n",
    "    def __delitem__(self, k):\n",
    "        \"\"\"Remove item associated with key k (raise KeyError if not found).\"\"\"\n",
    "        if not self.is_empty():\n",
    "            p = self._subtree_search(self.root(), k)\n",
    "            if k == p.key():\n",
    "                self.delete(p)                            # rely on positional version\n",
    "                return                                    # successful deletion complete\n",
    "            self._rebalance_access(p)                     # hook for balanced tree subclasses\n",
    "        raise KeyError('Key Error: ' + repr(k))\n",
    "        \n",
    "######################## Methods for section 11.2 ################################     \n",
    "    def _rebalance_insert(self, p): pass\n",
    "    def _rebalance_delete(self, p): pass\n",
    "    def _rebalance_access(self, p): pass\n",
    "    \n",
    "    def _relink(self, parent, child, make_left_child):\n",
    "        \"\"\"Relink parent node with child node (we allow child to be None).\"\"\"\n",
    "        if make_left_child:                     # make it a left child\n",
    "            parent._left = child\n",
    "        else:                                   # make it a right child\n",
    "            parent._right = child\n",
    "        if child is not None:                   # make child point to parent\n",
    "            child._parent                                                                                      = parent\n",
    "            \n",
    "    def _rotate(self, p):\n",
    "        \"\"\"Rotate Position p above its parent.\"\"\"\n",
    "        x = p._node\n",
    "        y = x._parent                           # we assume this exists\n",
    "        z = y._parent                           # grandparent (possibly None)\n",
    "        if z is None:\n",
    "            self._root = x                      # x becomes root\n",
    "            x._parent = None\n",
    "        else:\n",
    "            self._relink(z, x, y == z._left)    # x becomes a direct child of z\n",
    "        # now rotate x and y, including transfer of middle subtree\n",
    "        if x == y._left:\n",
    "            self._relink(y, x._right, True)     # x._right becomes left child of y\n",
    "            self._relink(x, y, False)           # y becomes right child of x\n",
    "        else:\n",
    "            self._relink(y, x._left, False)     # x._left becomes right child of y\n",
    "            self._relink(x, y, True)            # y becomes left child of x\n",
    "            \n",
    "    def _restructure(self, x):\n",
    "        \"\"\"Perform trinode restructure of Position x with parent/grandparent.\"\"\"\n",
    "        y = self.parent(x)\n",
    "        z = self.parent(y)\n",
    "        if (x == self.right(y)) == (y == self.right(z)):    # matching alignments\n",
    "            self._rotate(y)                                 # single rotation (of y)\n",
    "            return y                                        # y is new subtree root\n",
    "        else:                                               # opposite alignments\n",
    "            self._rotate(x)                                 # double rotation (of x)\n",
    "            self._rotate(x)\n",
    "            return x                                        # x is new subtree root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.5 Performance of a Binary Search Tree\n",
    "<img width=\"600\" alt=\"table-11.1\", src=\"https://user-images.githubusercontent.com/20944657/37075572-d24564a8-2215-11e8-9da8-c79930c1d1c0.png\">\n",
    "\n",
    "위는 이진 탐색 트리 $T$가 지원하는 연산들의 분석을 의미한다. 잘 보면 거의 모든 연산이 $h$에 의존함을 알 수 있다. $h$가 가장 낮을 때는 $h = \\lceil log(n+1) \\rceil - 1$을 갖지만 최악의 경우에는 $h = n$이 되어서 마치 맵을 리스트로 구현한 것 처럼 보일수도 있다. 다음 그림이 그 최악의 경우를 나타낸 것이다.\n",
    "\n",
    "<img width=\"150\" alt=\"figure-11.7\" src=\"https://user-images.githubusercontent.com/20944657/37075667-3df05e74-2216-11e8-93cf-483ddf5fff9a.png\">\n",
    "\n",
    "이 책에서 증명하는 것은 불가능하지만, 이진 탐색 트리의 평균적인 높이가 $O(logn)$ 임을 보일 수 있다. 그러나 이렇게 '평균'에 의존할 수 없고 확실하게 최악의 경우에도 높이가 $O(logn)$이길 원한다면 이 챕터의 뒷부분에서 다룰 다른 종류의 탐색 트리를 이용하는 것이 낫다.\n",
    "\n",
    "## 11.2 Balanced Search Trees\n",
    "랜덤하게 항목의 추가와 삭제를 계속 실시하는 경우 표준적인 이진 탐색 트리는 $O(logn)$의 예상 작동 시간을 갖는다. 그러나 일부 연산이 트리를 unbalanced하게 만든다면 $O(n)$ worst-case time이 걸릴 수도 있다. 이 챕터의 나머지에서는 더 나은 성능을 보장해주는 4개의 탐색 트리 알고리즘을 다룰 것이다. 4개 중 3개의 자료 구조(AVL트리, 스플레이 트리, 레드 블랙 트리)는 균형을 잡기 위해 표준적인 이진 탐색 트리의 모양을 바꾸고 높이를 낮춰주는 연산을 실시하는 방법을 이용한다.\n",
    "\n",
    "이진 탐색 트리의 균형을 다시 맞추는 방법은 **회전(rotation)**을 이용한다. 회전에서 우리는 아래의 그림과 같이 자식이 부모 위로 오게끔 \"회전\"을 실시한다. 이 때 회전에서는 부모와 자식 관계를 다시 설정해주는 것 밖에 하지 않으므로 $O(1)$의 시간이 걸린다.\n",
    "\n",
    "<img width=\"700\" alt=\"figure-11.8\" src=\"https://user-images.githubusercontent.com/20944657/37076044-0ff39566-2218-11e8-8953-399ffeea9491.png\">\n",
    "\n",
    "트리 내에서 균형을 맞추기 위해서는 여러 번의 회전을 통해 **trinode restructuring**을 해줘야 할 필요가 생긴다. 이는 아래의 그림과 같이 실시하면 되고, 역시나 $O(1)$의 시간이 걸린다.\n",
    "<img width=\"700\" alt=\"figure-11.9a\" src=\"https://user-images.githubusercontent.com/20944657/37082106-eead8bf2-222e-11e8-84c2-ce20bdb2a563.png\">\n",
    "<img width=\"700\" alt=\"figure-11.9b\" src=\"https://user-images.githubusercontent.com/20944657/37082107-eee39558-222e-11e8-85ec-5db2603ceaae.png\">\n",
    "<img width=\"700\" alt=\"figure-11.9c\" src=\"https://user-images.githubusercontent.com/20944657/37082109-ef2bf474-222e-11e8-835a-15364d57266b.png\">\n",
    "<img width=\"700\" alt=\"figure-11.9d\" src=\"https://user-images.githubusercontent.com/20944657/37082110-ef612676-222e-11e8-81f5-6991f6a020b9.png\">\n",
    "\n",
    "### Hooks for Rebalancing Operations\n",
    "리밸런싱 알고리즘을 위한 **훅**인 `_rebalance_insert(p)`, `_rebalance_delete(p)`, `_rebalance_access(p)`의 구현은 서브 클래스에서 이루어질 것이고, 역시나 **템플릿 메소드 디자인 패턴(template method design pattern)**을 이용한 사례이다.\n",
    "\n",
    "### Nonpublic Methods for Rotating and Restructuring\n",
    "`_rotate`, `_restructure` 유틸리티 메소드는 이진 탐색 트리의 rotation과 trinode restructuring을 구현한 메소드이다. 코드를 간단하게 만들기 위해 부모와 자식 노드를 연결해주는 `_relink` 유틸리티 메소드를 추가적으로 정의하였다. 자세한 사항은 위의 코드를 보면 된다.\n",
    "\n",
    "### Factory for Creating Tree Nodes\n",
    "우리의 코드에서 노드의 로우-레벨 정의는 `LinkedBinaryTree` 안의 중첩 클래스 `_Node`에 의해 이루어진다. 그런데 몇몇 트리 리밸런싱 알고리즘은 회전을 실행하기 위해 노드에 추가적인 정보를 저장하기를 원한다. 우리가 노드 인스턴스를 만들 때 `LinkedBinaryTree._Node`와 같이 qualified name을 이용하지 않고 `self._Node`를 이용한 것은 이렇게 서브 클래스가 노드에 추가적인 정보를 담기 위해 `_Node`를 오버라이드해서 쓸 수 있게끔 하기 위해서이다. 이러한 테크닉은 **팩토리 메소드 디자인 패턴(factory method design pattern)**의 예제라 할 수 있다. 팩토리 메소드 디자인 패턴은 *부모* 클래스의 메소드 내에서 생성된 객체의 생성을 서브클래스가 다루게끔 하는 것이다. 엄밀히 말하자면 추상 클래스에서 객체를 생성하는 부분을 추상 메소드로 만들고 이를 서브 클래스에서 구현하게끔 해야 한다. 지금의 예제에서는 `LinkedBinaryTree._Node` 대신 `self._Node`로 메소드를 구현하여, 서브클래스에서 `_Node`를 오버라이드해서 객체를 생성하는 부분을 필요한대로 다시 구현하면 모든 메소드가 그 새로 오버라이드된 객체 타입에 맞게끔 작동하게 해뒀기에 팩토리 메소드 디자인 패턴을 따른다고 할 수 있다.\n",
    "\n",
    "## 11.3 AVL Trees\n",
    "표준적인 이진 탐색 트리를 자료 구조로 이용하는 `TreeMap` 클래스는 효율적인 맵 자료 구조이긴 하지만 worst-case의 성능이 선형 시간이라는 문제가 있다. 이번 섹션에서는 간단한 balancing strategy를 이용해서 핵심적인 맵 연산의 worst-case 작동 시간이 로그가 되게끔 하는 법을 알아보자.\n",
    "\n",
    "### Definition of an AVL Tree\n",
    "**Height-Balance Property:** $T$의 모든 위치 $p$에 대해서 $p$의 자식들의 높이의 차이가 최대 1이다.\n",
    "\n",
    "위의 height-balance 성질을 만족하는 이진 탐색 트리 $T$를 **AVL 트리(AVL Tree)**라고 한다. 아래는 AVL 트리를 그림으로 나타낸 것인데, 노드 안의 수는 key이고 노드 밖의 숫자는 노드의 높이(height)를 나타낸다.\n",
    "\n",
    "<img width=\"400\" alt=\"figure-11.11\" src=\"https://user-images.githubusercontent.com/20944657/37089651-aaa014dc-2244-11e8-92f4-3c71ac2af824.png\">\n",
    "\n",
    "**Proposition 11.2:** $n$개의 항목을 저장하는 AVL 트리의 높이는 $O(logn)$이다.\n",
    "\n",
    "**Justification:** $n(h)$를 높이가 $h$인 AVL 트리의 최소 노드 수라 하자. 그러면 $n(1) = 1$, $n(2) = 2$이다. $h \\geq 3$일 때 높이가 $h$이면서 최소 노드를 갖는 AVL 트리는 그 서브트리로 높이가 각각 $h-1$, $h-2$인 AVL 트리를 가질 것이다. 루트까지 고려하면 $h \\geq 3$일 때 다음의 성질이 만족한다:\n",
    "\n",
    "$n(h) = 1 + n(h-1) + n(h-2)$.\n",
    "\n",
    "피보나치 수열에 대해 잘 알고 있다면 $n(h)$가 $h$에 대한 지수함수임을 알 수 있을 것이다.\n",
    "\n",
    "이제 이를 엄밀하게 보여보자. $n(h-1) \\gt n(h-2)$이므로 $n(h) > 2 \\cdot n(h-2)$이고, 그러면 $h-2i \\geq 1$에 대해\n",
    "\n",
    "$n(h) \\gt 2 \\cdot n(h-2) \\gt 4 \\cdot n(h-4) \\gt 8 \\cdot n(h-6) \\cdots \\gt 2^{i} \\cdot n(h-2i)$\n",
    "\n",
    "가 성립하고, $n(1)$과 $n(2)$의 값을 알고 있으므로 $i = \\lceil \\dfrac{h}{2} \\rceil - 1$ 이라 두면\n",
    "\n",
    "$n(h) \\gt 2^{\\lceil \\frac{h}{2} \\rceil - 1} \\cdot n(h-2\\lceil \\dfrac{h}{2} \\rceil+ 2)$\n",
    "\n",
    "$n(h) \\geq 2^{\\lceil \\frac{h}{2} \\rceil -1}n(1) \\geq 2^{\\frac{h}{2} - 1} $\n",
    "\n",
    "이제 로그를 취하면 $\\log(n(h)) \\gt \\dfrac{h}{2} - 1$이고,\n",
    "\n",
    "$h \\lt 2\\log(n(h)) + 2 $ 가 성립한다.\n",
    "\n",
    "### 11.3.1 Update Operations\n",
    "만약 그 자식들의 높이의 차이가 최대 1이면 그 위치는 **균형 잡힌(balanced)** 위치라 하고, 그렇지 않다면 **불균형한(unbalanced)** 위치라 한다. 이렇게 보면 AVL 트리의 height-balance property는 트리의 모든 위치가 균형 잡혀있어야 한다는 것과 같다.\n",
    "\n",
    "### Insertion\n",
    "AVL 트리에 새로운 항목을 잎(leaf) 위치 $p$에 추가하는 과정은 아래의 그림과 같다. 이 때 $p$부터 루트까지의 경로에서 가장 먼저 만나게 되는 불균형한 위치를 $z$라 하고, $z$의 자식 중 더 높은 자식을 $y$, $y$의 자식 중 더 높은 자식을 $x$라 한다(이 때 두 자식의 높이가 같을 수는 없고, $x$는 $p$의 조상이 된다($p$ 자기 자신일수도 있다)). 왼쪽의 그림은 새로운 노드 54를 추가해서 78과 44가 불균형해진 상황을 나타낸 그림이고, 오른쪽의 그림은 `restructure(x)`를 실행해서 균형이 회복된 상황을 나타낸다.\n",
    "\n",
    "<img style=\"float: left\" width=\"400\" alt=\"figure-11.12a\" src=\"https://user-images.githubusercontent.com/20944657/37090488-ee613540-2247-11e8-8839-b6a518b22aa3.png\">\n",
    "<img style=\"float: left\" width=\"400\" alt=\"figure-11.12b\" src=\"https://user-images.githubusercontent.com/20944657/37090489-ee99f84e-2247-11e8-9349-231e7a812b8e.png\">\n",
    "<div style=\"clear: both\"></div>\n",
    "\n",
    "이 과정을 조금 더 자세히 살펴보면 아래의 그림과 같다. trinode restructuring을 진행하는 과정에서 서브트리의 루트 높이가 $h+3$에서 다시 $h+2$로 회복하는 것을 확인할 수 있을 것이다. 이렇게 되면 일시적으로 불균형 상태에 놓이게 된 $z$의 ancestor들이 다시 균형을 찾게 되고, 한 번의 restructuring 만으로도 **전역적으로(globally)** 트리의 height-balance 성질을 회복할 수 있게 된다.\n",
    "\n",
    "<img width=\"400\" alt=\"figure-11.13a\" src=\"https://user-images.githubusercontent.com/20944657/37090720-c12bfafa-2248-11e8-9413-ebd7a6b8dded.png\">\n",
    "<img width=\"400\" alt=\"figure-11.13b\" src=\"https://user-images.githubusercontent.com/20944657/37090721-c15a0e04-2248-11e8-9240-fbf7d859cc95.png\">\n",
    "<img width=\"400\" alt=\"figure-11.13c\" src=\"https://user-images.githubusercontent.com/20944657/37090722-c18895f8-2248-11e8-9ae1-e4a6f133a364.png\">\n",
    "\n",
    "### Deletion\n",
    "이제 삭제를 살펴보자. 삭제한 노드의 부모 노드를 $p$라 하자. 그러면 $p$부터 $T$의 루트까지의 경로 중에 불균형해진 노드가 존재한다. 노드를 삭제하는 과정은 아래의 그림과 같다. $p$부터 루트까지의 경로에서 가장 먼저 만나게 되는 불균형한 위치를 $z$라 하고, $z$의 자식 중 더 높은 자식을 $y$, $x$는 다음의 두 케이스에 의해 결정된다: $y$의 자식 중 더 높이가 높은 것이 있으면 그 자식을 $x$로 둔다. 그게 아니라면 $x$는 $y$와 똑같은 방향의 $y$의 자식으로 둔다. 예를 들어 $y$가 $z$의 오른쪽 자식이면 $x$는 $y$의 오른쪽 자식이 된다. 왼쪽의 그림은 32 노드를 지워서 불균형해진 상황을 나타낸 그림이고, 오른쪽의 그림은 `reconstruction(x)`를 실행해서 균형이 회복된 상황을 나타낸다.\n",
    "\n",
    "<img style=\"float: left\" width=\"400\" alt=\"figure-11.14a\" src=\"https://user-images.githubusercontent.com/20944657/37091037-0eba39a2-224a-11e8-987c-7f13a765dedd.png\">\n",
    "<img style=\"float: left\" width=\"400\" alt=\"figure-11.14b\" src=\"https://user-images.githubusercontent.com/20944657/37091039-0ee8fb84-224a-11e8-905d-5f1138930739.png\">\n",
    "<div style=\"clear: both\"></div>\n",
    "\n",
    "여기서는 운이 좋게도 서브트리의 높이가 4로 유지되었지만 항상 이렇게 되는 것은 아니고, 삭제 후 균형을 찾고 나면 서브트리의 높이가 1 감소하는 경우가 생긴다. 따라서 삭제의 경우 $b$의 서브트리 내에서 height-balance 성질은 **국소적으로(locally)** 회복되는 것이 보장되지만, 전역적으로 균형이 회복되는 것이 보장되지는 않는다. 따라서 $z$의 균형을 맞춘 후에 우리는 계속해서 경로를 따라 올라가며 불균형한 위치가 있는지 찾아야 한다. AVL 트리의 높이가 $O(logn)$ 이므로 $O(logn)$ trinode restructuing으로 height-balance 성질을 회복하는 것이 가능하다.\n",
    "\n",
    "### Performance of AVL Trees\n",
    "명제 11.2에 의해 $n$개의 항목을 갖는 AVL 트리의 높이가 $O(logn)$ 임이 보장되므로 표준적인 이진 탐색 트리 연산은 아래의 표와 같은 성능을 갖는다.\n",
    "\n",
    "<img width=\"500\" alt=\"table-11.2\" src=\"https://user-images.githubusercontent.com/20944657/37091288-f05cb498-224a-11e8-8af1-bd6f533c3efe.png\">\n",
    "<img width=\"500\" alt=\"figure-11.15\" src=\"https://user-images.githubusercontent.com/20944657/37091309-03709568-224b-11e8-8fde-d550ea4be8bf.png\">\n",
    "\n",
    "### 11.3.2 Python Implementation\n",
    "아래는 `AVLTreeMap` 클래스의 파이썬 구현 코드이다. 위에서는 Insertion과 Deletion에서의 rebalancing이 전역적인지 국소적인지에 대한 논의가 있었지만 아래의 코드에서는 둘을 통합하여 `_rebalance`를 구현하였다. `_rebalance`에서는 $p$부터 올라가면서 trinode restructuring을 실시했음에도 높이가 변하지 않는 경우 리밸런싱을 중단한다. 높이가 변하지 않는다는 것은 그 ancestor들의 높이도 변화가 없다는 것이므로 균형이 회복된 것을 의미하기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AVLTreeMap(TreeMap):\n",
    "    \"\"\"Sorted map implementation using an AVL tree.\"\"\"\n",
    "    \n",
    "    #---------------- nested _Node class --------------------\n",
    "    class _Node(TreeMap._Node):\n",
    "        \"\"\"Node class for AVL maintains height value for balancing.\"\"\"\n",
    "        __slots__ = '_height'               # additional data member to store height\n",
    "        \n",
    "        def __init__(self, element, parent=None, left=None, right=None):\n",
    "            super().__init__(element, parent, left, right)\n",
    "            self._height = 0                # will be recomputed during balancing\n",
    "\n",
    "        def left_height(self):\n",
    "            return self._left._height if self._left is not None else 0\n",
    "\n",
    "        def right_height(self):\n",
    "            return self._right._height if self._right is not None else 0\n",
    "    \n",
    "    #--------------- positional-based utility methods --------------------\n",
    "    def _recompute_height(self, p):\n",
    "        p._node._height = 1 + max(p._node.left_height(), p._node.right_height())\n",
    "        \n",
    "    def _isbalanced(self, p):\n",
    "        return abs(p._node.left_height() - p._node.right_height()) <= 1\n",
    "    \n",
    "    def _tall_child(self, p, favorleft = False):\n",
    "        # if two children have same heights, decision depends on the favorleft Boolean value.\n",
    "        if p._node.left_height() + (1 if favorleft else 0) > p._node.right_height():\n",
    "            return self.left(p)\n",
    "        else:\n",
    "            return self.right(p)\n",
    "        \n",
    "    def _tall_grandchild(self, p):\n",
    "        child = self._tall_child(p)\n",
    "        # if child is on left, favor left grandchild; else favor right grandchild\n",
    "        alignment = (child == self.left(p))\n",
    "        return self._tall_child(child, alignment)\n",
    "    \n",
    "    def _rebalance(self, p):\n",
    "        while p is not None:\n",
    "            old_height = p._node._height\n",
    "            if not self._isbalanced(p):\n",
    "                # perform trinode restructuing, setting p to resulting root,\n",
    "                # and recompute new local heights after the restructuing\n",
    "                p = self._restructure(self._tall_grandchild(p))\n",
    "                self._recompute_height(self.left(p))\n",
    "                self._recompute_height(self.right(p))\n",
    "            self._recompute_height(p)\n",
    "            if p._node._height == old_height:\n",
    "                p = None\n",
    "            else:\n",
    "                p = self.parent(p)\n",
    "                \n",
    "    #------------------ override balancing hooks ------------------------------\n",
    "    def _rebalance_insert(self, p):\n",
    "        self._rebalance(p)\n",
    "        \n",
    "    def _rebalance_delete(self, p):\n",
    "        self._rebalance(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 11.4 Splay Trees\n",
    "다음으로 살펴볼 트리 구조는 **스플레이 트리(splay tree)**이다. 스플레이 트리는 다른 균형 탐색 트리와 크게 다른데, 트리의 높이 상한이 로그가 되게끔 강제하지 않기 때문이다. 사실 스플레이 트리에는 기본적인 이진 탐색 트리 외에 추가적인 높이, 균형, 보조적인 자료 구조 등의 어떠한 요구사항도 존재하지 않는다. 스플레이 트리의 효율성은 **스플레이(splaying)**라 불리는 move-to-root 연산에 의존한다. 이는 추가, 제거, 탐색 과정에서 만나게 되는 가장 아래의 위치 $p$를 루트로 이동시키는 연산이다. 직관적으로 볼 때 스플레이 연산은 더 자주 접근이 일어나는 원소일수록 루트와 가깝게 둠으로써 일반적인 탐색 시간을 줄여준다. 놀라운 점은 이렇게 하는 것만으로도 스플레이 트리의 추가, 제거, 탐색 연산의 amortized 작동 시간이 로그가 된다는 것이다.\n",
    "\n",
    "### 11.4.1 Splaying\n",
    "이동하려는 노드 $x$의 부모를 $y$, 그 부모를 $z$라 두자. 그러면 스플레이에는 아래와 같이 3개의 케이스가 존재한다.\n",
    "- **zig-zig:** $x$와 그 부모 $y$가 모두 왼쪽 자식이거나 오른쪽 자식이다.\n",
    "\n",
    "<img style=\"float: left\" width=300 alt=\"figure-11.16a\" src=\"https://user-images.githubusercontent.com/20944657/37098287-e398a6a2-2260-11e8-9ece-130caf2857b1.png\">\n",
    "<img style=\"float: left\" width=300 alt=\"figure-11.16b\" src=\"https://user-images.githubusercontent.com/20944657/37098300-eda05410-2260-11e8-8fdb-78566ae11b29.png\">\n",
    "<div style=\"clear: both\"></div>\n",
    "\n",
    "- **zig-zag:** $x$와 $y$ 중 하나는 왼쪽 자식이고 다른 하나는 오른쪽 자식이다.\n",
    "\n",
    "<img style=\"float: left\" width=\"300\" alt=\"figure-11.17a\" src=\"https://user-images.githubusercontent.com/20944657/37098444-391761ae-2261-11e8-81e1-c304d4abb031.png\">\n",
    "<img style=\"float: left\" width=\"300\" alt=\"figure-11.17b\" src=\"https://user-images.githubusercontent.com/20944657/37098446-39590ac8-2261-11e8-84bb-b3eb05df92fc.png\">\n",
    "<div style=\"clear: both\"></div>\n",
    "\n",
    "- **zig:** $x$가 조부모를 갖지 않는다.\n",
    "\n",
    "<img style=\"float: left\" width=\"300\" alt=\"figure-11.18a\" src=\"https://user-images.githubusercontent.com/20944657/37098447-39953d90-2261-11e8-8899-18412bde29d8.png\">\n",
    "<img style=\"float: left\" width=\"300\" alt=\"figure-11.18b\" src=\"https://user-images.githubusercontent.com/20944657/37098448-39c88b82-2261-11e8-8f5f-bf98d601f4b0.png\">\n",
    "<div style=\"clear: both\"></div>\n",
    "\n",
    "**스플레이**는 $x$가 $T$의 루트가 될 때까지 위의 restructuring을 계속해서 반복한다. 아래의 그림들은 스플레이가 일어나는 과정을 잘 보여준다.\n",
    "<img width=\"400\" alt=\"figure-11.19a\" src=\"https://user-images.githubusercontent.com/20944657/37098614-ae0f8a54-2261-11e8-90d6-39c164c85c1a.png\">\n",
    "<img width=\"400\" alt=\"figure-11.19b\" src=\"https://user-images.githubusercontent.com/20944657/37098618-aee360cc-2261-11e8-862a-2b99570639f4.png\">\n",
    "<img width=\"400\" alt=\"figure-11.19c\" src=\"https://user-images.githubusercontent.com/20944657/37098621-afac2cc8-2261-11e8-847b-6769cd69d78b.png\">\n",
    "<img width=\"400\" alt=\"figure-11.20d\" src=\"https://user-images.githubusercontent.com/20944657/37098622-afe3e88e-2261-11e8-9822-50d41a6275ae.png\">\n",
    "<img width=\"400\" alt=\"figure-11.20e\" src=\"https://user-images.githubusercontent.com/20944657/37098623-b01d1fb4-2261-11e8-8b5b-4538b044455c.png\">\n",
    "<img width=\"400\" alt=\"figure-11.20f\" src=\"https://user-images.githubusercontent.com/20944657/37098625-b0509ba0-2261-11e8-9949-c801ecab6a54.png\">\n",
    "\n",
    "### 11.4.2 When to Splay\n",
    "스플레이는 다음과 같은 상황에서 실행한다:\n",
    "- key $k$를 탐색할 때 만약 $p$에서 $k$를 찾았다면 $p$를 스플레이한다. 만약 찾지 못했다면 탐색이 종료된 위치를 스플레이한다. 예를 들어 위의 스플레이 예제는 성공적으로 key 14를 찾았거나 key 15를 찾지 못한 경우의 예제로 볼 수 있다.\n",
    "- key $k$를 추가할 때 $k$가 추가된 노드를 스플레이한다. 예를 들어 위의 스플레이 예제는 14가 새로 추가된 key일 경우의 예제로 볼 수 있다. 스플레이 트리에 반복적으로 노드를 추가할 경우의 스플레이를 그림으로 나타내면 아래와 같다.\n",
    "- key $k$를 제거할 때 제거된 노드의 부모 위치 $p$를 스플레이한다.\n",
    "\n",
    "### 11.4.3 Python Implementation\n",
    "스플레이 트리의 성능의 수학적 분석은 복잡하지만(see Section 11.4.4), 스플레이 트리의 *구현*은 표준적인 이진 탐색 트리의 간단한 응용으로 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SplayTreeMap(TreeMap):\n",
    "    \"\"\"Sorted map implementation using a splay tree.\"\"\"\n",
    "    #------------------------ splay operation -----------------------------\n",
    "    def _splay(self, p):\n",
    "        while p != self.root():\n",
    "            parent = self.parent(p)\n",
    "            grand = self.parent(parent)\n",
    "            if grand is None:\n",
    "                # zig case\n",
    "                self._rotate(p)\n",
    "            elif (parent == self.left(grand)) == (p == self.left(parent)):\n",
    "                # zig-zig case\n",
    "                self._rotate(parent)                   # move PARENT up\n",
    "                self._rotate(p)                        # then move p up\n",
    "            else:\n",
    "                # zig-zag case\n",
    "                self._rotate(p)                        # move p up\n",
    "                self._rotate(p)                        # move p up again\n",
    "                \n",
    "    #------------------------ override balancing hooks -----------------------------\n",
    "    def _rebalance_insert(self, p):\n",
    "        self._splay(p)\n",
    "        \n",
    "    def _rebalance_delete(self, p):\n",
    "        if p is not None:\n",
    "            self._splay(p)\n",
    "            \n",
    "    def _rebalance_access(self, p):\n",
    "        self._splay(p)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.5 (2,4) Trees\n",
    "이번 섹션에서는 **(2,4) 트리**라고 알려진 자료 구조를 다룬다. (2,4)트리는 내부 노드가 2개 이상의 자식을 가질 수 있는 **다방향 탐색 트리(multiway search tree)**라 알려진 일반적인 구조의 특별한 예제이다. 먼저 다방향 탐색 트리에 대해 알아보자.\n",
    "\n",
    "## 11.5.1 Multiway Search Trees\n",
    "일반적인 트리는 자식 수에 제한이 없이 정의되므로, 어떻게 일반적인 트리를 다방향 탐색 트리로 이용할 수 있는지 알아보자.\n",
    "\n",
    "### Definition of a Multiway Search Tree\n",
    "\n",
    "<img width=\"500\" alt=\"figure-11.23a\" src=\"https://user-images.githubusercontent.com/20944657/37143462-97af931a-22fe-11e8-8a96-21ba7c42e043.png\">\n",
    "\n",
    "\n",
    "순서 트리의 노드를 $w$라 하고, $d$개의 자식을 갖는 $w$를 **d-노드(d-node)**라 하자. 이제 다방향 탐색 트리를 다음의 성질을 갖는 순서 트리 $T$로 정의하자.\n",
    "- 모든 내부 노드는 적어도 두개의 자식 노드를 갖는다. 즉 모든 내부 노드는 $d \\geq 2$인 d-노드이다.\n",
    "- $c_{1}, ... , c_{d}$을 자식으로 갖는 $T$의 모든 내부 d-노드 $w$는 $d - 1$개의 key-value 페어 $(k_{1}, v_{1}), ..., (k_{d-1}, v_{d-1})$, where $k_{1} \\leq \\cdots \\leq k_{d-1}$의 순서 집합을 저장한다.\n",
    "- 관례적으로 $k_{0} = -\\infty$, $k_{d} = +\\infty$라 두자. 그러면 $c_{i}, i = 1, ..., d$를 루트로 하는 서브트리 $w$의 노드에 저장된 모든 $(k,v)$에 대해 $k_{i-1} \\leq k \\leq k_{i}$가 성립한다.\n",
    "\n",
    "말이 어려우니 좀 풀어쓰면, 다방향 탐색 트리의 d-노드 $w$에는 $d-1$개의 key-value 페어가 저장된다. 그런데 만약 $w$에 가상의 $k_{0} = -\\infty$와 $k_{d} = +\\infty$가 들어있다고 생각하면, 자식 노드 $c_{i}$를 루트로 하는 서브트리의 모든 원소들은 반드시 $w$에 저장된 두 key의 \"사이\"에 있게 된다. 이는 이후 다방향 탐색 트리의 탐색 알고리즘에서 중요한 역할을 한다.\n",
    "\n",
    "다방향 탐색 트리에서 외부 노드는 어떠한 정보도 저장하지 않으며 위치만 차지하는 \"placeholder\" 역할만 하게 된다. 이러한 외부 노드는 `None`으로 효율적으로 표현할 수 있다.\n",
    "\n",
    "**Proposition 11.7:** $n$개의 항목을 갖는 다방향 탐색 트리는 $n+1$개의 외부 노드를 갖는다.\n",
    "\n",
    "### Searching in a Multiway Tree\n",
    "다방향 탐색 트리 $T$에서 key $k$를 찾는 것은 간단하다. 아래의 그림을 보면 이해가 갈 것이다. 첫번째 그림은 12의 탐색이 실패한 경우이고, 두번째 그림은 24의 탐색이 성공한 경우이다.\n",
    "\n",
    "<img width=\"500\" alt=\"figure-11.23b\" src=\"https://user-images.githubusercontent.com/20944657/37143463-97e1d7da-22fe-11e8-8614-a636935da9fd.png\">\n",
    "\n",
    "<img width=\"500\" alt=\"figure-11.23c\" src=\"https://user-images.githubusercontent.com/20944657/37143464-98138b04-22fe-11e8-99e1-f07c19dc3401.png\">\n",
    "\n",
    "### Data Structures for Representing Multiway Search Trees\n",
    "위의 탐색 과정에서 볼 수 있듯이, 다방향 탐색 트리에서 중요한 연산 중 하나는 각각의 $w$에서 $k$보다 같거나 큰 key 중에서 가장 작은 key를 찾는 것이고, 이를 위해서는 `find_ge(k)` 메소드의 이용이 가능한 sorted map을 이용하는 것이 자연스럽다. 즉, *주* 자료 구조인 다방향 탐색 트리를 *보조* 자료 구조인 sorted map이 보조해준다. ordered map을 이용해서 ordered map을 표현한다는 것이 순환논리처럼 보일 수도 있겠지만, 간단한 해결책을 이용해서 더 발전된 해결책을 만들어나가는 **부트스트래핑(bootstrapping)** 테크닉을 이용하면 이러한 순환 구조를 피할 수 있다.\n",
    "\n",
    "다방향 탐색 트리를 구현할 때 보조 자료 구조로는 `SortedTableMap`을 이용할 것이다. 탐색 도중 key $k$를 찾은 경우 연결된 value를 반환하고, 찾지 못한 경우 그 $c_{i}$를 반환하므로 보조 자료 구조의 $k_{i}$가 $(v_{i}, c_{i})$와 연결되게끔 하는 것이 좋다. $d_{max}$를 $T$의 최대 자식의 수라고 하고 $h$를 $T$의 높이라 하자. 각각의 $w$ 내부에서의 탐색은 바이너리 서치를 이용하므로 $O(d_{max})$ 시간 복잡도를 가질 것이다. 따라서 다방향 탐색 트리의 탐색 시간은 $O(h\\log d_{max})$이고, 만약 $d_{max}$가 상수라면 탐색 시간은 $O(h)$가 된다.\n",
    "\n",
    "다방향 탐색 트리의 효율성을 위해서는 높이를 가능한 한 낮게 유지해야 한다. 이제 $h$를 $O(\\log n)$으로 유지하면서 $d_{max}$를 4로 제한하는 (2,4) 트리를 알아보자.\n",
    "\n",
    "### 11.5.2 (2,4)-Tree Operations\n",
    "보조 자료 구조의 크기를 작게 유지하면서도 균형 트리가 되게끔 하는 다방향 탐색 트리를 **(2,4) 트리**라고 한다. (2,4) 트리는 다음의 성질을 만족해야 한다:\n",
    "- **Size Property:** 모든 내부 노드는 최대 4개의 자식 노드를 갖는다\n",
    "- **Depth Property:** 모든 외부 노드는 같은 깊이(depth)를 갖는다.\n",
    "\n",
    "Size Property에 따르면 $d_{max} = 4$가 성립하고, 그러면 내부 노드의 secondary map을 ordered array나 unordered list 중 어떤 방식으로 표현하는지에 관계 없이 모든 연산이 $O(1)$ 시간 안에 끝나게 된다. Depth Property를 이용하면 (2,4) 트리의 높이와 관련된 중요한 명제를 도출할 수 있다.\n",
    "\n",
    "**Proposition 11.8:** $n$개의 항목을 저장하는 (2,4) 트리의 높이는 $O(\\log n)$이다.\n",
    "\n",
    "**Justification:** Size Property에 의해 깊이 1엔 최대 $4$개의 노드, 깊이 2엔 최대 $4^{2}$의 노드가 있고, 외부 노드에는 최대 $4^{h}$개의 노드가 있다. 이제 Depth Property와 (2,4)트리의 정의를 이용하면 깊이 1에는 최소 2개의 노드가 있어야 하고, 깊이 2에는 최소 2^{2}개의 노드가 있어야 하고, 외부 노드에는 최소 $2^{h}$개의 노드가 있어야 한다. 만약 깊이가 1 증가하는데 노드가 최소 2배로 증가하지 않으면 루트에서 외부 노드로 내려오는 경로 중 적어도 하나는 깊이가 1 낮을 것이기 때문이다. 이제 명제 11.7을 이용하여 이를 식으로 정리하면,\n",
    "\n",
    "$2^{h} \\leq n + 1 \\leq 4^{h}$\n",
    "\n",
    "$h \\leq \\log(n+1) \\leq 2h$\n",
    "\n",
    "가 성립하고, 식을 정리하면 증명이 끝난다.\n",
    "\n",
    "### Insertion\n",
    "새로운 항목 $(k,v)$를 추가하기 위해서는 우선 $k$를 탐색한다. key $k$가 트리 내에 없다고 가정하면, 탐색은 외부 노드 $z$에서 종료되었을 것이다. 이제 $w$를 $z$의 부모 노드라 하면, 새로운 항목을 노드 $w$에 추가하고 $w$의 새로운 자식 노드 $y$(외부 노드)를 $z$의 왼쪽에 추가한다.\n",
    "\n",
    "이러한 추가 메소드는 Depth Property를 유지하지만 4-노드에 새로운 항목을 추가한 경우 Size Property가 깨져서 **오버플로우(overflow)**가 생길 수 있다. 이럴 때는 **스플릿(split)** 연산을 해줘야 한다.\n",
    "\n",
    "- $w$를 $w'$와 $w''$으로 분리한다. 이 때,\n",
    "    - $w'$는 key $k_{1}, k_{2}$와 자식 $c_{1},c_{2},c_{3}$을 갖는 3-노드이다.\n",
    "    - $w''$는 key $k_{4}$와 자식 $c_{4}, c_{5}$를 갖는 2-노드이다.\n",
    "- 만약 $w$가 $T$의 루트라면 새로운 루트 노드 $u$를 만든다. 아니라면 $w$의 부모 노드를 $u$라 둔다.\n",
    "- $k_{3}$을 $u$에 추가하고 $w'$와 $w''$를 $u$의 자식으로 만든다. 즉, $w'$와 $w''$를 각각 $u$의 $c_{i}$, $c_{i+1}$로 만든다.\n",
    "\n",
    "스플릿 연산으로 인해 다시 오버플로우가 나타날 경우 또 스플릿 연산을 해주면 된다. 아래의 그림을 보자.\n",
    "\n",
    "<img width=\"400\" alt=\"figure-11.26a\" src=\"https://user-images.githubusercontent.com/20944657/37145860-67656ce6-2305-11e8-9309-8a98358331c9.png\">\n",
    "<img width=\"400\" alt=\"figure-11.26b\" src=\"https://user-images.githubusercontent.com/20944657/37145843-5c590aec-2305-11e8-92a6-33ab9ce8b81c.png\">\n",
    "<img width=\"400\" alt=\"figure-11.26c\" src=\"https://user-images.githubusercontent.com/20944657/37145844-5c8b0984-2305-11e8-8442-9bb0e7d68566.png\">\n",
    "<img width=\"400\" alt=\"figure-11.26d\" src=\"https://user-images.githubusercontent.com/20944657/37145845-5cc0097c-2305-11e8-9d51-5baf38534606.png\">\n",
    "<img width=\"400\" alt=\"figure-11.26e\" src=\"https://user-images.githubusercontent.com/20944657/37145847-5d282868-2305-11e8-8d9f-0f2c15ff10e0.png\">\n",
    "<img width=\"400\" alt=\"figure-11.26f\" src=\"https://user-images.githubusercontent.com/20944657/37145848-5d75f4f8-2305-11e8-9b31-d956b0e50aff.png\">\n",
    "<div style=\"clear: both\"></div>\n",
    "\n",
    "### Analysis of Insertion in a (2,4) Tree\n",
    "$d_{max}$가 최대 4이므로 각각의 레벨에서 새로운 key $k$의 위치를 찾는 데에는 $O(1)$ 시간이 걸리고, 전체적으로는 $O(\\log n)$ 시간이 걸린다. 노드에 새로운 key와 자식 노드를 추가하는 것은 $O(1)$ 시간이면 충분하고, 따라서 스플릿 연산도 $O(1)$ 시간 복잡도를 갖는다. 스플릿을 계속 실행할 경우의 시간 복잡도는 그 높이에 비례하므로 $O(\\log n)$이 된다. 따라서 (2,4)트리에서 추가는 $O(\\log n)$ 시간 복잡도를 갖는다.\n",
    "\n",
    "### Deletion\n",
    "(2,4)트리에서 삭제를 하게 되면 언제나 외부 노드를 자식으로 갖는 노드 $w$를 지우게 된다. 이는 만약 내부 노드에 저장된 $(k_{i}, v_{i})$를 지워야하는 경우가 생기더라도 그 값을 $c_{i}$를 루트로 하는 서브 트리의 가장 오른쪽 내부노드 $z$의 마지막 항목과 교체하고, $z$를 지우기 때문이다.\n",
    "\n",
    "항목을 지울 때에는 추가할 때와 달리 오버플로우가 일어나지 않지만, 2-노드의 한개 뿐인 항목을 지우는 **언더플로우(underflow)**가 나타난다. 이 경우 만약 $w$의 형제노드 $s$ 중 3-노드이거나 4-노드가 있으면 **transfer** 연산을 실행하고, 그렇지 않다면 $w$를 형제 노드와 합쳐 $w'$를 만드는 **fusion** 연산을 실행해야 한다.\n",
    "<img width=\"400\" alt=\"figure-11.28a\" src=\"https://user-images.githubusercontent.com/20944657/37146697-e39b2074-2307-11e8-86bb-6bddd086cbb9.png\">\n",
    "<img width=\"400\" alt=\"figure-11.28b\" src=\"https://user-images.githubusercontent.com/20944657/37146698-e3cbf730-2307-11e8-8573-0a98610ae62e.png\">\n",
    "<img width=\"400\" alt=\"figure-11.28c\" src=\"https://user-images.githubusercontent.com/20944657/37146699-e3fe4014-2307-11e8-851b-d36f3b53e823.png\">\n",
    "<img width=\"400\" alt=\"figure-11.28d\" src=\"https://user-images.githubusercontent.com/20944657/37146700-e43433b8-2307-11e8-9995-11b6feff9095.png\">\n",
    "<img width=\"400\" alt=\"figure-11.28e\" src=\"https://user-images.githubusercontent.com/20944657/37146701-e46842a2-2307-11e8-894e-cd2e257a9a3d.png\">\n",
    "<img width=\"400\" alt=\"figure-11.28f\" src=\"https://user-images.githubusercontent.com/20944657/37146703-e4a3073e-2307-11e8-8b9e-b1415210651e.png\">\n",
    "<img width=\"400\" alt=\"figure-11.28f\" src=\"https://user-images.githubusercontent.com/20944657/37146704-e50b7e9a-2307-11e8-9a05-48b6090311a4.png\">\n",
    "<img width=\"400\" alt=\"figure-11.28f\" src=\"https://user-images.githubusercontent.com/20944657/37146706-e541e89a-2307-11e8-9e4d-58506baaedc6.png\">\n",
    "<div style=\"clear: both\"></div>\n",
    "\n",
    "그런데 퓨전 연산은 $w$의 부모 $u$에 언더플로우를 발생시킬 수도 있다. 이런 경우 $u$에 다시 트랜스퍼나 퓨전 연산을 실시하면 된다. 따라서 퓨전 연산의 횟수는 트리의 높이에 의해 bound되고, $O(\\log n)$이 된다. 만약 언더플로우가 루트까지 퍼진다면 루트를 지우면 된다.\n",
    "\n",
    "<img width=\"400\" alt=\"figure-11.29a\" src=\"https://user-images.githubusercontent.com/20944657/37146843-49d34be6-2308-11e8-9831-6754b1fe570e.png\">\n",
    "<img width=\"400\" alt=\"figure-11.29b\" src=\"https://user-images.githubusercontent.com/20944657/37146844-4a054704-2308-11e8-905b-581babd223fc.png\">\n",
    "<img width=\"400\" alt=\"figure-11.29c\" src=\"https://user-images.githubusercontent.com/20944657/37146845-4a39d992-2308-11e8-9a8d-685e621e221e.png\">\n",
    "<img width=\"400\" alt=\"figure-11.29d\" src=\"https://user-images.githubusercontent.com/20944657/37146848-4a6dae98-2308-11e8-8e7c-8e105fc62e1c.png\">\n",
    "<div style=\"clear: both\"></div>\n",
    "\n",
    "### Performance of (2,4) Trees\n",
    "sorted map의 관점에서 봤을 때 (2,4) 트리의 성능은 AVL 트리의 성능과 동일하다. 두 트리 모두 대부분의 연산에 대해 로그 시간 복잡도를 갖는다. $n$개의 항목을 갖는 (2,4) 트리의 시간 복잡도 분석은 다음과 같다.\n",
    "\n",
    "- $n$개의 항목을 갖는 (2,4) 트리의 높이는 $O(\\log n)$이다.\n",
    "- 스플릿, 트랜스퍼, 퓨전 연산은 $O(1)$ 시간이 걸린다.\n",
    "- 탐색, 추가, 삭제는 $O(\\log n)$ 노드를 방문한다.\n",
    "\n",
    "## 11.6 Red-Black Trees\n",
    "AVL 트리와 (2,4) 트리가 좋은 성질을 갖고 있긴 하지만 단점도 있다. AVL 트리는 삭제 연산을 한 후에 많은 restructure operation(rotation)을 해야 할 수도 있고, (2,4) 트리는 추가나 삭제 후에 스플릿이나 퓨전 연산을 많이 실시해야 할 수도 있다. 그러나 레드-블랙 트리(red-black tree)는 균형을 유지하기 위해 $O(1)$번의 구조 변화만 해주면 되는 장점을 갖는다.\n",
    "\n",
    "**레드-블랙 트리(red-black tree)**는 다음의 성질을 만족하게끔 노드들이 black이나 red로 칠해진 이진 탐색 트리이다:\n",
    "- **Root Property:** 루트는 black이다.\n",
    "- **Red Property:** red 노드의 자식들은 black이다.\n",
    "- **Depth Property:** 자식이 없거나 하나의 자식만 갖는 모든 노드들은 같은 **black depth**를 갖는다. black depth는 black ancestor의 수를 의미한다.\n",
    "\n",
    "<img width=\"500\" alt=\"figure-11.30\" src=\"https://user-images.githubusercontent.com/20944657/37147174-63377552-2309-11e8-914c-cbd0925357b7.png\">\n",
    "\n",
    "앞에서 본 (2,4) 트리와 레드-블랙 트리에는 매우 밀접한 관계가 있다. 사실, (2,4) 트리는 레드-블랙 트리로 바꿀 수 있고, 레드-블랙 트리는 (2,4) 트리로 바꿀 수 있다. 이러한 관계를 이해하면 이후 추가, 삭제 연산을 이해하는 데 도움이 될 것이다. 만약 레드-블랙 트리가 주어진다면 모든 red 노드 $w$를 그 부모 노드와 합치고, $w$의 자식들은 부모의 ordered children로 둬서 (2,4) 트리로 바꾸는 것이 가능하다. 아래의 그림을 보자.\n",
    "\n",
    "<img width=\"500\" alt=\"figure-11.31\" src=\"https://user-images.githubusercontent.com/20944657/37147323-e3148bac-2309-11e8-970d-535a305576e9.png\">\n",
    "\n",
    "역으로 (2,4) 트리를 레드-블랙 트리로 바꾸는 것도 가능하다. 다음의 그림처럼 2-노드, 3-노드, 4-노드의 경우를 나눠서 바꾸면 된다.\n",
    "<table>\n",
    "<tr>\n",
    "<td><img src=\"https://user-images.githubusercontent.com/20944657/37147366-0b3da956-230a-11e8-87e3-5a8775c798e1.png\"></td>\n",
    "<td> $\\iff$ </td>\n",
    "<td><img src=\"https://user-images.githubusercontent.com/20944657/37147365-0af8a3a6-230a-11e8-8a0c-0510a58f44ab.png\"></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"https://user-images.githubusercontent.com/20944657/37147369-0c488fd2-230a-11e8-8930-d51ab7d5ec94.png\"></td>\n",
    "<td> $\\iff$ </td>\n",
    "<td><img src=\"https://user-images.githubusercontent.com/20944657/37147367-0b7a5a7c-230a-11e8-9d2f-a5c919505afc.png\"></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"https://user-images.githubusercontent.com/20944657/37147371-0cb08aba-230a-11e8-88f2-d514a8ce8fc6.png\"></td>\n",
    "<td> $\\iff$ </td>\n",
    "<td><img src=\"https://user-images.githubusercontent.com/20944657/37147370-0c7cb690-230a-11e8-97ed-614682fcc33a.png\"></td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "**Proposition 11.9:** $n$개의 항목을 저장하는 레드-블랙 트리의 높이는 $O(\\log n)$이다.\n",
    "\n",
    "**Justification:** $n$개의 항목을 갖는 레드-블랙 트리를 $T$라 하고, 그 높이를 $h$라 하자. 자식이 없거나 하나의 자식만 갖는 모든 노드들의 common black depth를 $d$라 두고, $T'$를 $T$와 연결된 (2,4)트리, $h'$를 $T'$의 높이(`None`인 외부 노드 제외)라 하자. 그러면 레드-블랙 트리와 (2,4) 트리의 일치성으로 인해 $h' = d$가 성립한다. 이는 위에서 레드-블랙 트리를 (2,4) 트리로 바꿀 때 red 노드를 전부 black 노드에 합쳤다는 걸 생각하면 쉽게 알 수 있을 것이다. 그러면 명제 11.8에 의해 $d = h' \\leq \\log(n+1)-1$이 성립한다. 이제 Red Property를 이용하면 $h \\leq 2d$ 임을 보일 수 있다. $h \\gt 2d$라고 가정해보자. 그러면 루트에서 외부 노드까지의 경로에 $d$보다 많은 red 노드가 존재하는데, 루트 노드가 black이므로 이는 경로의 가장 밑 부분에 두 개의 red 노드가 연속으로 나올 수 밖에 없음을 의미한다. 그러면 이는 Red Property에 위배되므로 모순이다.\n",
    "\n",
    "이를 종합하면 $ h \\leq 2d = 2\\log(n+1)-2$이고, 명제 8.8에서 $\\log(n+1)-1 \\leq h$를 안다. 따라서,\n",
    "\n",
    "$ \\log(n+1)-1 \\leq h \\leq 2\\log(n+1)-2$가 성립한다.\n",
    "\n",
    "### 11.6.1 Red-Black Tree Operations\n",
    "### Insertion & Deletion\n",
    "설명이 너무나도 복잡해서 생략합니다. 책을 직접 읽고 이해하시는 것이 좋을 것 같습니다.\n",
    "\n",
    "### Performance of Red-Black Trees\n",
    "sorted map ADT의 관점에서 볼 때 레드-블랙 트리의 성능은 AVL트리나 (2,4) 트리의 성능과 일치한다. 대부분의 연산이 로그 시간 bound를 갖는다. 그럼에도 레드-블랙 트리가 갖는 이점이 있다면, 최악의 경우 로그 수 만큼의 structural change를 실시해줘야 하는 AVL트리, (2,4)트리와 달리 추가나 삭제의 과정에서 **상수(constant number)번만 restructuing operation**을 실시해도 된다는 것이다.  \n",
    "\n",
    "**Proposition 11.10:** $n$개의 항목을 저장하고 있는 레드-블랙 트리에 새로운 항목을 추가하는 데 걸리는 시간은 $O(\\log n)$이고, $O(\\log n)$번의 recoloring과 최대 한번의 trinode restructuing이 필요하다.\n",
    "\n",
    "**Justification:** 새로운 항목을 추가하기 위해서는 아래로의 탐색을 실시하고, 새로운 leaf 노드를 만들어야 한다. 만약 double-red violation이 발생하는 경우 `Case 2`로 인해 로그 수 만큼의 recoloring을 하게 될 수도 있지만, `Case 1`이 발생하는 경우 한 번의 trinode resturctuing만 해주면 double-red 문제가 해결되므로 최대 한번의 trinode restructing으로 충분하다.\n",
    "\n",
    "**Proposition 11.11:** $n$개의 항목을 저장하고 있는 레드-블랙 트리에서 항목을 제거하는 데 걸리는 시간은 $O(\\log n)$이고, $O(\\log n)$번의 recoloring과 최대 2번의 restructuring operation이 필요하다.\n",
    "\n",
    "**Justification:** 레드-블랙 트리에서의 삭제는 표준적인 이진 탐색 트리의 삭제와 같은 과정으로 이루어지므로 $O(\\log n)$ 시간이 걸린다. 그러나 레드-블랙 트리에서는 삭제된 노드의 부모 노드로부터 루트까지 경로를 따라 다시 균형을 맞추는 작업을 진행해줘야 한다.\n",
    "\n",
    "`Case 1`의 경우 한 번의 trinode restructuring 연산으로 균형을 다시 맞출 수 있다. `Case 2`는 로그 수 만큼의 recoloring을 해줘야 할 수도 있지만 기껏해봐야 최대 두개까지의 노드의 색만 바꿔주면 된다. `Case 3`이 발생하면 rotation을 실시하고 `Case 1`이나 `Case 2`의 경우를 적용해야 한다.\n",
    "\n",
    "종합하면, 최악의 경우 Case 2에서 $O(\\log n)$ recoloring을 실시하고, Case 3에서 한번의 rotation을 실시하고, Case 1에서 한번의 trinode restructuring을 실시하게 된다.\n",
    "\n",
    "### 11.6.2 Python Implementation\n",
    "Insertion과 Deletion에 관한 부분까지 책을 참고하며 여기까지 따라왔다면 코드는 쉽게 이해할 수 있을 것이다. 이 때 꼭 언급해야 할 부분이 있다면 노드의 삭제 후 실행되는 hook인 `_rebalance_hook`이다. 이 훅이 실행될 때는 노드가 이미 제거되어 노드에 대한 정보가 없다. 이 훅은 삭제된 노드의 *부모 노드*에 대해 실행된다. 그러나 운이 좋게도 레드-블랙 트리의 성질을 이용해서 부모 노드의 특징만 갖고도 삭제된 노드에 대한 정보를 유추하는 것이 가능하다. 만약 $p$가 삭제된 노드의 부모 노드라면, 다음이 반드시 성립한다:\n",
    "- 만약 $p$가 자식이 없다면, 삭제된 노드는 red leaf 였을 것이다. 이 때는 어떠한 성질도 위배되지 않는다.(Exercise R-11.26.)\n",
    "\n",
    "- 만약 $p$가 하나의 자식을 갖는다면, 하나 남은 자식이 red leaf인 경우를 제외하면 삭제된 노드는 black leaf였을 것이고, black deficit이 발생한다. (Exercise R-11.27.)\n",
    "\n",
    "- 만약 $p$가 두개의 자식 노드를 갖는다면, 삭제된 노드는 하나의 red 자식 노드를 갖는 black 노드였을 것이다. 이 때 그 red 자식 노드를 black으로 만들어줘야 한다. (Exercise R-11.28.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RedBlackTreeMap(TreeMap):\n",
    "    \"\"\"Sorted map implementation using a red-black tree.\"\"\"\n",
    "    class _Node(TreeMap._Node):\n",
    "        \"\"\"Node class for red-black tree maintains bit that denotes color.\"\"\"\n",
    "        __slots__ = '_red'        # add additional data member to the Node class\n",
    "        \n",
    "        def __init__(self, element, parent=None, left=None, right=None):\n",
    "            super().__init__(element, parent, left, right)\n",
    "            self._red = True      # new node red by default\n",
    "            \n",
    "    #---------------- positional-based utility methods -----------------------------\n",
    "    # we consider a nonexistent child to be trivially black\n",
    "    def _set_red(self, p): p._node._red = True\n",
    "    def _set_black(self, p): p._node._red = False\n",
    "    def _set_color(self, p, make_red): p._node._red = make_red\n",
    "    def _is_red(self, p): return p is not None and p._node._red\n",
    "    def _is_red_leaf(self, p): return self._is_red(p) and self.is_leaf(p)\n",
    "    \n",
    "    def _get_red_child(self, p):\n",
    "        \"\"\"Return a red child of p (or None if no such child).\"\"\"\n",
    "        for child in (self.left(p), self.right(p)):\n",
    "            if self._is_red(child):\n",
    "                return child\n",
    "        return None\n",
    "    \n",
    "    #----------------- support for insertions ---------------------------------------\n",
    "    def _rebalance_insert(self, p):\n",
    "        self._resolve_red(p)                            # new node is always red\n",
    "        \n",
    "    def _resolve_red(self, p):\n",
    "        if self.is_root(p):\n",
    "            self._set_black(p)                          # make root black\n",
    "        else:\n",
    "            parent = self.parent(p)\n",
    "            if self._is_red(parent):                    # double red problem\n",
    "                uncle = self.sibling(parent)\n",
    "                if not self._is_red(uncle):             # Case 1: misshapen 4-node\n",
    "                    middle = self._restructure(p)       # do trinode restructuring\n",
    "                    self._set_black(middle)             # and then fix colors\n",
    "                    self._set_red(self.left(middle))\n",
    "                    self._set_red(self.right(middle))\n",
    "                else:                                   # Case 2: overfull 5-node\n",
    "                    grand = self.parent(parent)\n",
    "                    self._set_red(grand)                # grandparent becomes red\n",
    "                    self._set_black(self.left(grand))   # its children becomes black\n",
    "                    self._set_black(self.right(grand))\n",
    "                    self._resolve_red(grand)            # recur at red grandparent\n",
    "                    \n",
    "    #----------------- support for deletions ---------------------------------------\n",
    "    def _rebalance_delete(self, p):\n",
    "        if len(self) == 1:\n",
    "            self._set_black(self.root())                # special case: ensure that root is black\n",
    "        elif p is not None:\n",
    "            n = self.num_children(p)\n",
    "            if n == 1:                                  # deficit exists unless child is a red leaf\n",
    "                c = next(self.children(p))\n",
    "                if not self._is_red_leaf(c):\n",
    "                    self._fix_deficit(p, c)\n",
    "            elif n == 2:                                # removed black node with red child\n",
    "                if self._is_red_leaf(self.left(p)):\n",
    "                    self._set_black(self.left(p))\n",
    "                else:\n",
    "                    self._set_black(self.right(p))\n",
    "                    \n",
    "    def _fix_deficit(self, z, y):\n",
    "        \"\"\"Resolve black deficit at z, where y is the root of z's heavier subtree.\"\"\"\n",
    "        if not self._is_red(y): # y is black; will apply Case 1 or 2\n",
    "            x = self._get_red_child(y)\n",
    "            if x is not None: # Case 1: y is black and has red child x; do \"transfer\"\n",
    "                old_color = self._is_red(z)\n",
    "                middle = self._restructure(x)\n",
    "                self._set_color(middle, old_color)\n",
    "                self._set_black(self.left(middle))\n",
    "                self._set_black(self.right(middle))\n",
    "            else: # Case 2: y is black, but no red children; recolor as \"fusion\"\n",
    "                self._set_red(y)\n",
    "                if self._is_red(z):\n",
    "                    self._set_black(z)             # this resolves the problem\n",
    "                elif not self.is_root(z):\n",
    "                    self._fix_deficit(self.parent(z), self.sibling(z))  # recur upward\n",
    "        else: # Case 3: y is red; rotate misaligned 3-node and repeat\n",
    "            self._rotate(y)\n",
    "            self._set_black(y)\n",
    "            self._set_red(z)\n",
    "            if z == self.right(y):\n",
    "                self._fix_deficit(z, self.left(z))\n",
    "            else:\n",
    "                self._fix_deficit(z, self.right(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
