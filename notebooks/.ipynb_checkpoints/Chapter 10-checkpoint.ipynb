{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chpater 10 Maps, Hash Tables and Skip Lists\n",
    "## 10.1 Maps and Dictionaries\n",
    "파이썬에서 가장 중요한 자료 구조를 고르라면 당연히 **dict** 클래스일 것이다. 파이썬 딕셔너리는 **딕셔너리**라고 알려진 추상화를 제공하는데, 이 딕셔너리에서는 유니크한 **key**가 관련된 **value**로 매핑된다. 딕셔너리가 나타내는 key와 value 사이의 관계로 인해 딕셔너리는 흔히 **연관 배열(associative arrays)** 혹은 **맵(maps)**이라고 불린다. 이 책에서는 파이썬의 `dict` 클래스를 지칭할때는 `dictionary`라 하고, 일반적인 자료 형의 개념을 다룰 때는 `map`이라 부를 것이다.\n",
    "\n",
    "간단한 예제로, 아래의 그림은 국가의 이름과 통화의 단위를 연결한 맵의 예제이다.\n",
    "\n",
    "<img width=\"600\" alt=\"figure-10.1\" src=\"https://user-images.githubusercontent.com/20944657/36952791-abd5636e-2057-11e8-9ee1-7df76f4f86b3.png\">\n",
    "\n",
    "key(국가 이름)는 유니크하지만 value(통화 단위)는 유니크할 필요가 없다. 예를 들어, 스페인과 그리스는 둘 다 통화 단위로 유로를 이용한다. 맵은 인덱싱을 위해 `currency['Greece']`와 같이 배열과 같은 문법을 이용한다. 이 때 주어진 key의 value를 새로운 value로 리매핑하려면 `currency['Greece'] = 'Drachma'`와 같은 문법을 이용할 수도 있다. 표준적인 배열과 다르게, 맵의 인덱스들은 연속적일 필요가 없고, 인덱스가 숫자여야 할 필요도 없다. 맵의 일반적인 활용은 다음과 같다.\n",
    "- 대학의 정보 시스템(information system)은 학생 ID를 key로 이용해서 그 학생의 관련된 정보(이름, 주소, 학점)를 관리한다.\n",
    "- DNS(domain-name system)는 `www.wiley.com`과 같은 호스트 네임을 IP(internet-protocol)에 매핑한다.\n",
    "- 소셜 미디어 사이트는 (숫자가 아닌) 유저 이름을 key로 이용해서 유저의 관련된 정보에 효과적으로 매핑한다.\n",
    "- 컴퓨터 그래픽 시스템은 `turquoise`와 같은 색 이름을 (64,224,208)과 같은 색의 RGB(red-green-blue) 숫자와 매핑한다.\n",
    "- 파이썬은 딕셔너리를 이용해서 각각의 네임스페이스를 표현한다. 예를 들어 `pi`와 같은 식별자를 `3.14159`와 같은 객체로 연결한다.\n",
    "\n",
    "우리는 이번 챕터와 다음 챕터에서 키를 이용해서 값을 찾는 탐색 과정이 매우 효율적으로 이루어질 수 있고 다양한 상황에서 활용될 수 있음을 보일 것이다.\n",
    "\n",
    "### 10.1.1 The Map ADT\n",
    "이번 섹션에서는 **맵 ADT(map ADT)**를 소개하고, 파이썬의 built-in `dict` 클래스와 일관성 있게끔 맵의 동작들을 정의할 것이다. 먼저 맵 $M$에서 가장 중요한 5가지 동작들을 살펴보자:\n",
    "- **M[k]:** $M$에서 key `k`와 관련된 value `v`를 반환한다. 만약 없다면 `KeyError`가 발생한다. 파이썬에서는 이 메소드는 스페셜 메소드인 `__getitem__`으로 구현된다.\n",
    "- **M[k] = v:** $M$에서 key `k`에 value `v`를 연결시킨다. 만약 이미 key `k`와 연결된 value가 있다면 새로운 value로 교환한다. 파이썬에서는 스페셜 메소드인 `__setitem__`으로 구현된다.\n",
    "- **del M[k]:** 맵 $M$에서 key가 `k`인 항목을 제거한다. 만약 $M$에 그런 항목이 없다면 `KeyError`가 발생한다. 파이썬에서는 스페셜 메소드인 `__delitem__`으로 구현된다.\n",
    "- **len(M):** 맵 $M$에 있는 항목들의 수를 반환한다. 파이썬에서는 스페셜 메소드인 `__len__`으로 구현된다.\n",
    "- **iter(M):** 맵의 `keys` 시퀀스를 생성하는 맵의 iteration을 반환한다. 파이썬에서는 스페셜 메소드인 `__iter__`으로 구현된다.\n",
    "\n",
    "위의 다섯가지 동작은 맵의 핵심적인 기능인 쿼리, 추가, 수정, key-value 페어의 제거, 이 페어들을 모두 보고하는 능력을 모두 설명하기에 중요하다. 추가적인 편의를 위해 맵 $M$은 다음의 동작들을 지원해야 한다:\n",
    "- **k in M:** 맵이 key `k`인 항목을 포함하고 있다면 True를 반환한다. 파이썬에서는 스페셜 메소드인 `__contains__`으로 구현된다.\n",
    "- **M.get(k, d=None):** 맵에 key `k`가 존재하면 `M[k]`를 반환한다. 만약 없다면 default value인 `d`를 반환한다. 이 메소드는 `KeyError`에 대한 걱정 없이도 `M[k]`를 쿼리할 수 있게 해준다.\n",
    "- **M.setdefault(k, d):** 만약 맵 안에 key `k`가 존재한다면 `M[k]`를 반환한다. 만약 키 `k`가 존재하지 않는다면 `M[k]`를 `d`로 만들고 그 값을 반환한다.\n",
    "- **M.pop(k, d=None):** 맵에서 key `k`와 연결된 항목을 제거하고 그 value `v`를 반환한다. 만약 key `k`가 맵 안에 없다면 기본 값 `d`를 반환한다 (만약 매개변수 `d`가 `None`이면 `KeyError`를 반환한다).\n",
    "- **M.popitem():** 맵에서 임의의 key-value 페어를 제거하고 그 `(k,v)` 튜플을 반환한다. 맵이 비어있다면 `KeyError`가 발생한다.\n",
    "- **M.clear():** 맵에서 모든 key-value 페어를 제거한다\n",
    "- **M.keys():** $M$의 모든 key에 대한 set-like view를 반환한다.\n",
    "- **M.values():** $M$의 모든 value에 대한 set-like view를 반환한다.\n",
    "- **M.items():** $M$의 모든 항목의 (k,v) 튜플에 대한 set-like view를 반환한다.\n",
    "- **M.update(M2):** 맵 $M2$의 모든 (k,v) 페어에 대해 `M[k] = v`로 할당한다.\n",
    "- **M == M2:** 맵 $M$과 $M2$가 동일한 key-value 연결관계를 갖고 있을 때 True를 반환한다.\n",
    "- **M != M2:** 맵 $M$과 $M2$가 동일하지 않은 key-value 연결관계를 갖고 있을 때 True를 반환한다.\n",
    "\n",
    "### 10.1.2 Application: Counting Word Frequencies\n",
    "맵을 이용하는 대표적인 사례로 문서에서 단어의 사용 빈도를 카운트하는 예제를 보자. 자세한 설명은 생략한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wordcount(filename):\n",
    "    freq = {}\n",
    "    for piece in open(filename).read().lower().split():\n",
    "        # only consider alphabetic characters within this piece\n",
    "        word = ''.join(c for c in piece if c.isalpha())\n",
    "        if word:\n",
    "            freq[word] = 1 + freq.get(word, 0)\n",
    "            \n",
    "    max_word = ''\n",
    "    max_count = 0\n",
    "    for (w,c) in freq.items():\n",
    "        if c > max_count:\n",
    "            max_word = w\n",
    "            max_count = c\n",
    "    print('The most frequent word is', max_word)\n",
    "    print('Its number of occurences is', max_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.3 Python's MutableMapping Abstract Base Class\n",
    "Section 2.4.3에서는 **추상 기초 클래스(abstract base class)**의 개념을 소개하고, 파이썬의 `collections` 모듈에서 그러한 클래스들의 역할을 설명했었다. 이러한 기초 클래스에서 추상 메소드로 선언된 메소드들은 구상 서브클래스에서 반드시 구현되어야 한다. 그러나 추상 기초 클래스는 이 추상 메소드들을 이용하는 다른 메소드들의 *구체적인* 구현을 제공하기도 한다(이는 **템플릿 메소드 디자인 패턴(template method design pattern**의 예제이다).\n",
    "\n",
    "`collections` 모듈은 우리의 현재 논의와 관련된 두개의 추상 기초 클래스를 제공한다(`Mapping`과 `MutableMapping` 클래스). `Mapping` 클래스는 파이썬의 `dict` 클래스에 의해 지원되는 모든 nonmutating 메소드를 포함하고 있고, `MutableMapping` 클래스는 이를 mutating 메소드까지 포함하게끔 확장시킨다. 우리가 앞에서 맵 ADT라고 정의한 것은 파이썬의 `collections` 모듈 중 `MutableMapping` 추상 기초 클래스와 유사하다.\n",
    "\n",
    "이러한 추상 기초 클래스의 중요성은 이 클래스가 사용자-정의 맵 클래스를 만드는 데 도움이 된다는 것에 있다. 구체적으로 말하면, `MutableMapping` 클래스는 처음 말한 5개의 `__getitem__`, `__setitem__`, `__delitem__`, `__len__`, `__iter__`를 제외하고는 모든 동작들에 대한 구체적인 구현을 제공한다. 다양한 자료 구조를 이용해서 맵의 추상화를 구현할 때 우리는 이 5개의 핵심 동작만 정의하면 나머지 동작들은 모두 `MutableMapping` 부모 클래스에서 상속받을 수 있다.\n",
    "\n",
    "`MutableMapping` 클래스를 더 잘 이해하기 위해서 어떻게 구체적인 동작들이 5개의 추상화에 의존하는지 예제를 통해 살펴보자. 예를 들어 `k in M`과 같은 문법을 지원하는 `__contains__` 메소드는 다음과 같이 구현된다.\n",
    "\n",
    "```python\n",
    "def __contains__(self, k):\n",
    "    try:\n",
    "        self[k]               # access via __getitem__ (ignore result)\n",
    "        return True\n",
    "    except KeyError:\n",
    "        return False          # attempt failed\n",
    "```\n",
    "\n",
    "`setdefault` 메소드에서도 비슷한 방식을 이용한다.\n",
    "```python\n",
    "def setdefault(self, k, d):\n",
    "    try:\n",
    "        return self[k]             # if __getitem__ succeeds, return value\n",
    "    except:                        # otherwise:\n",
    "        self[k] = d                # set default value with __setitem__\n",
    "        return d                   # and return that newly assigned value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MutableMapping` 클래스의 다른 구상 메소드의 구현은 연습문제로 남긴다.\n",
    "\n",
    "### 10.1.4 Our MapBase Class\n",
    "우리는 이번 챕터와 다음 챕터를 통해서 맵 ADT의 서로 다른 여러가지 구현을 제공할 것이고, 그러면서 여러 자료 구조에서 나타나는 장점과 단점의 상충관계를 설명할 것이다. 아래의 그림은 그 클래스들의 미리보기라 할 수 있다.\n",
    "<img width=\"600\" alt=\"figure-10.2\" src=\"https://user-images.githubusercontent.com/20944657/36953627-91608d8a-205f-11e8-9d58-95f672690dfd.png\">\n",
    "\n",
    "`MutableMapping` 추상 기초 클래스는 맵을 구현할 때 아주 유용하지만, 코드 재활용성을 증대시키기 위해서 우리는 `MutableMapping`의 서브클래스인 `MapBase` 클래스를 새로 정의할 것이다. 이 `MapBase` 클래스는 컴포지션 디자인 패턴을 지원하기 위해 고안되었다. 구체적으로 말하자면, `MapBase` 클래스는 `MutableMapping` 클래스의 유용한 메소드들을 상속받으면서도 추가적으로 nonpublic 중첩 클래스인 `_Item` 클래스를 정의한다. 이 `_Item` 클래스의 인스턴스는 key와 value를 동시에 저장할 수 있다. 이 클래스는 Section 9.2.1에서 봤던 `PriorityQueueBase` 클래스의 `_Item` 클래스와 유사하지만, 맵에서는 key을 이용한 비교를 지원한다는 점에서 차이가 있다. 맵을 구현할 때는 항상 동등성(equality)의 개념을 잘 정의해서 새로 항목을 추가할 때 이미 저장된 key 중에 새로 추가하려는 key와 같은 것이 있는 지 확인할 수 있게끔 해줘야 한다. 또한 `<` 연산자를 이용한 key 사이의 비교는 이후 **sorted map ADT**(Section 10.3)에서 중요하게 등장할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import MutableMapping\n",
    "class MapBase(MutableMapping):\n",
    "    \"\"\"Our own abstract base class that includes a nonpublic _Item class.\"\"\"\n",
    "    \n",
    "    #--------------------- nest _Item class -------------------------------\n",
    "    class _Item:\n",
    "        \"\"\"Lighweight composite to store key-value pairs as map items.\"\"\"\n",
    "        __slots__ = '_key', '_value'\n",
    "        \n",
    "        def __init__(self, k, v):\n",
    "            self._key = k\n",
    "            self._value = v\n",
    "            \n",
    "        def __eq__(self, other):\n",
    "            return self._key == other._key    # compare items based on their keys\n",
    "        \n",
    "        def __ne__(self, other):\n",
    "            return not (self == other)        # opposite of __eq__\n",
    "        \n",
    "        def __lt__(self, other):\n",
    "            return self._key < other._key     # compare items based on their keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.5 Simple Unsorted Map Implementation\n",
    "`MapBase` 클래스를 이용해서 매우 간단한 맵 ADT의 구현을 해보자. 아래의 코드는 파이썬 리스트 내에 key-value 페어를 임의의 순서로 저장하는 `UnsortedTableMap` 클래스 예제이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UnsortedTableMap(MapBase):\n",
    "    \"\"\"Map implementation using an unordered list.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Create an empty map.\"\"\"\n",
    "        self._table = []\n",
    "        \n",
    "    def __getitem__(self, k):\n",
    "        \"\"\"Return value associated with key k (raise KeyError if not found).\"\"\"\n",
    "        for item in self._table:\n",
    "            if k == item._key:\n",
    "                return item._value\n",
    "        raise KeyError('Key Error: ' + repr(k))\n",
    "    \n",
    "    def __setitem__(self, k, v):\n",
    "        \"\"\"Assign value v to key k, overwriting existing value if present.\"\"\"\n",
    "        for item in self._table:\n",
    "            if k == item._key:                                   # Found a match:\n",
    "                item._value = v                                  # reassign value\n",
    "                return                                           # and quit\n",
    "        # did not find match for key\n",
    "        self._table.append(self._Item(k,v))\n",
    "        \n",
    "    def __delitem__(self, k):\n",
    "        \"\"\"Remove item associated with key k (raise KeyError if not found.\"\"\"\n",
    "        for j in range(len(self._table)):\n",
    "            if k == self._table[j]._key:\n",
    "                self._table.pop(j)\n",
    "                return\n",
    "        raise KeyError('Key Error: ' + repr(k))\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Return number of items in the map.\"\"\"\n",
    "        return len(self._table)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \"\"\"Generate iteration of the map's keys.\"\"\"\n",
    "        for item in self._table:\n",
    "            yield item._key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 Hash Tables\n",
    "이번 섹션에서는 파이썬 `dict` 클래스의 구현에 실제로 사용되고 있으면서, 맵을 구현하기 위한 가장 실용적인 자료 구조 중 하나인 **해쉬 테이블(table)**을 소개한다. 직관적으로, 맵 $M$은 `M[k]`와 같이 키를 인덱스로 이용한다. 예를 들어 맵 $M$이 $N \\geq n$인 $N$에 대해 $0$부터 $N-1$까지의 정수 중에서 인덱스를 갖는 $n$개의 항목을 갖는다고 하자. 이 경우에 아래와 같은 **lookup table**을 이용해서 맵을 표현할 수 있다.\n",
    "\n",
    "<img width=\"600\" alt=\"figure-10.3\" src=\"https://user-images.githubusercontent.com/20944657/36954280-37019dc0-2064-11e8-9516-10d7db25132f.png\">\n",
    "\n",
    "이러한 표현 방식을 이용할 경우 우리는 테이블의 $k$ 인덱스에 key $k$와 연결된 값을 저장한다(빈 슬롯을 표현하는 방법이 있다고 가정하자). 이 때 기본적인 `__getitem__`, `__setitem__`, `__delitem__`은 $O(1)$ worst-case 시간에 실행될 수 있다. 이러한 프레임워크를 더 일반적인 맵의 환경으로 확장하려면 두 가지 문제가 있다. 첫째, $N \\gg n$일 경우 길이가 $N$인 배열을 유지하는 것은 비효율적이다. 둘째, 맵의 key가 정수일 것이라는 가정은 일반적이지 못하다.\n",
    "\n",
    "해쉬 테이블이 이러한 문제를 해결하기 위해 사용한 새로운 개념은 일반적인 키를 테이블 인덱스로 매핑하기 위해 **해쉬 함수(hash function)**을 이용한 것이다. 이상적이라면 해쉬 함수에 의해서 key가 $0$부터 $N-1$까지 잘 분포되어야 할 것이지만, 실제로는 두개 이상의 key가 같은 인덱스로 매핑된다. 따라서 우리는 아래와 같이 테이블을 **bucket array**로 개념화한다. 각각의 버켓은 해쉬 함수로 인해 특정 인덱스로 오게 된 항목들의 집합을 관리한다(공간을 아끼기 위해 빈 버켓은 None으로 교체된다).\n",
    "\n",
    "<img width=\"600\" alt=\"figure-10.3\" src=\"https://user-images.githubusercontent.com/20944657/36954440-651a8680-2065-11e8-90c8-8235e70cfc18.png\">\n",
    "\n",
    "### 10.2.1 Hash Functions\n",
    "**해쉬 함수(hash function)**, $h$, 의 목표는 key $k$를 $[0, N-1]$ 안의 정수로 매핑하는 것이다. 이 때 $N$은 해쉬 테이블을 위한 bucket array의 수용능력(capacity)이다. 이제 맵은 해쉬 함수 값 $h(k)$를 이용해서 $k$ 대신 $h(k)$를 bucket array $A$의 인덱스로 이용한다. 즉, $(k,v)$를 버켓의 $A[h(k)]$에 저장한다.\n",
    "\n",
    "만약 같은 해쉬값을 갖는 두 개 이상의 key가 존재할 경우 두 다른 항목이 $A$의 같은 버켓에 매핑된다. 이 경우 **충돌(collision)**이 일어났다고 한다. collision을 다루는 방법은 여러가지가 있고 나중에 이를 자세히 다룰 것이다. 그러나 지금 간단히 말하자면 가장 좋은 전략은 애초에 collision이 일어날 일이 없게 하는 것이다. 우리는 collision을 충분히 최소화하면서 맵의 key를 매핑해주는 해쉬 함수를 \"좋은\" 해쉬 함수라고 말한다. 또 실용적인 이유에서 볼 때에는 해쉬 함수가 계산하기에 빠르고 쉽기를 원하기도 한다.\n",
    "\n",
    "일반적으로는 해쉬 함수의 평가 $h(k)$가 두 부분으로 이루어져있다고 본다. 첫번째는 key $k$를 정수로 매핑해주는 **hash code**이고, 두번째는 해쉬 코드를 인덱스 범위 $[0, N-1]$ 내로 매핑해주는 **압축 함수(compression function)**이다.\n",
    "\n",
    "<img width=\"400\" alt=\"figure-10.5\" src=\"https://user-images.githubusercontent.com/20944657/36954635-b05f3cd4-2066-11e8-9c0a-4b3af575a116.png\">\n",
    "\n",
    "이렇게 해쉬 함수를 두 부분으로 나누는 접근방식의 장점은 해쉬 코드와 관련된 부분이 해쉬 테이블의 구체적인 크기와 무관하게 된다는 점이다. 이는 어떠한 크기의 해쉬 테이블에도 사용될 수 있는 일반적인 해쉬 코드의 발전을 가능하게 한다. 압축 함수만이 해쉬 테이블의 크기에 의존한다. 이렇게 되면 현재 맵에 저장된 항목들의 수에 따라 해쉬 테이블 내의 버켓 배열이 동적으로 리사이징되는 것이 가능해져서 굉장히 편리하다(See Section 10.2.3.)\n",
    "\n",
    "### Hash Codes\n",
    "해쉬 함수가 처음으로 취하는 행동은 맵의 임의의 key $k$를 이용해서 $k$의 **해쉬 코드**라 불리는 정수를 계산하는 것이다. 이 정수는 $[0, N-1]$ 안에 있어야 할 필요가 없고, 음수일 수도 있다. 우리는 키에 할당된 해쉬 코드의 집합이 가능한 한 충돌(collision)을 피하기를 원한다. 만약 해쉬 코드에서 충돌이 일어난다면 압축 함수가 충돌을 피할 수 있는 가능성은 없다. 이제 해쉬 코드의 이론을 다뤄보고 실제 해쉬 코드가 파이썬에서 어떻게 구현되는지 알아보자.\n",
    "\n",
    "### Treating the Bit Representation as an Integer\n",
    "우리의 해쉬 코드 정수의 비트 이하의 비트를 이용해서 표현되는 자료형 $X$는 그 비트의 정수 표현을 해쉬 코드로 이용하는 것이 가능하다. 예를 들어 key 314의 해쉬 코드는 314가 될 수 있다. 3.14와 같은 부동소수점의 해쉬 코드는 부동소수 표현의 비트를 정수로 표현하고 그 정수를 해쉬 코드로 쓸 수 있다.\n",
    "\n",
    "만약 그 비트 표현이 해쉬 코드의 비트 수보다 길다면 위와 같은 방식은 사용할 수 없다. 예를 들어 파이썬은 32비트 해쉬 코드를 이용한다. 만약 부동소수가 64비트로 표현된다면 그 비트는 해쉬 코드로 이용할 수 없다. 이를 피하는 방법 중 하나는 high-order 32비트만 이용하는 것이다. 물론 이렇게 하면 원래 key의 50%가 무시될 뿐 아니라 많은 key가 일부 비트만 빼고 동일하다면 collision을 피할 수도 없게 될 것이다.\n",
    "\n",
    "더 나은 접근법은 64비트 키의 high-order와 low-order 부분을 어떻게든 잘 조합해서 32비트 해쉬 코드를 만드는 것이다. 간단한 방법 중 하나는 각각이 32비트 수이므로 둘을 더하는 것이다(오버플로우는 무시한다). 아니면, 두 비트의 `exclusive-or`을 취하는 방법도 있다. 이렇게 두 요소를 합하는 접근방식은 그 이진 표현이 32비트 정수의 $n$-튜플, $(x_{0}, x_{1}, ... , x_{n-1})$,로 표현될 수 있는 임의의 객체 $x$에 대해서도 확장될 수 있다. 예를 들어 $x$의 해쉬 코드는 $\\sum_{i=0}^{n-1} x_{i}$나 $x_{0} \\oplus x_{1} \\oplus \\cdots \\oplus x_{n-1}$로 나타낼 수 있다. 이 때 $\\oplus$는 파이썬에서 `^`로 표현되는 `exclusive-or` 연산을 의미한다.\n",
    "\n",
    "### Polynomial Hash Codes\n",
    "위의 합이나 `exclusive-or` 해쉬 코드는 튜플 $(x_{0}, x_{1}, ..., x_{n-1})$로 표현될 수 있는 객체이지만 그 튜플 내에서 $x_{i}$의 순서가 중요한 경우에는 좋은 선택이 아니다. 예를 들어 문자열 $s$안의 유니코드 값을 합하는 16비트 해쉬 코드를 생각해보자. 이 해쉬 코드는 불행히도 많은 collision을 발생시킨다. 예를 들어 \"temp01\"과 \"temp10\"은 이 함수에 의해 똑같은 해쉬 코드를 갖게 된다. \"stop\", \"tops\", \"pots\", \"spot\"도 마찬가지이다. 이러한 문제를 해결하기 위한 좋은 방법으로는 $x_{i}$의 순서를 고려하는 해쉬 코드를 이용하는 것이 있다. 그러한 방식을 이용하는 더 나은 방법으로는 0이 아닌 상수 $a \\neq 1$을 고른 후,\n",
    "\n",
    "$x_{0}a^{n-1} + x_{1}a^{n-2} + \\cdots + x_{n-2}a + x_{n-1}$ 을 해쉬 코드로 이용하는 것이 있다.\n",
    "\n",
    "수학적으로 말하면 이는 단순히 $(x_{0}, x_{1}, ..., x_{n-1}$을 계수로 이용하는 $a$의 다항식일 뿐이다. 따라서 이 해쉬코드는 **polynomial hash code**라고 불린다. Horner's rule을 이용하면 이 다항식은 다음과 같이 계산할 수 있다.\n",
    "\n",
    "$x_{n-1} + a(x_{n-2} + a(x_{n-3} + \\cdots + a(x_{2} + a(x_{1} + ax_{0}))\\cdots))$\n",
    "\n",
    "직관적으로, 이 다항 해쉬 코드는 각각의 요소의 영향력을 퍼트리기 위한 방법으로 제곱(power)을 이용한다. 물론 일반적인 컴퓨터에서 다항식의 계산이 해쉬 코드의 비트 수를 이용해서 이루어지므로 오버플로우가 발생할 수 있다. 그러나 우리는 다른 key와 $x$의 차이를 구분하는 것에 관심이 있으므로 그러한 오버플로우는 무시해도 된다. 그럼에도 항상 주의해야 할 것은 오버플로우가 일어나고 있다는 사실을 인지하고, 만약 오버플로우가 일어날 경우 low-order nonzero bit를 이용할 수 있게끔 상수 $a$를 잘 정해줘야 한다는 것이다.\n",
    "\n",
    "예를 들어 실험 연구에 따르면 영어 단어 문자열을 갖고 작업할 때에는 33, 37, 39, 41이 $a$의 값으로 적합하다고 알려져 있다. 50,000개 이상의 영어 단어 리스트를 갖고 작업할 때 33, 37, 39, 41의 $a$ 값을 이용하면 7개 이하의 collision이 발생한다.\n",
    "\n",
    "### Cyclic-Shift Hash Codes\n",
    "다항 해쉬 코드의 변종으로는 $a$를 곱하는 대신 부분합에 특정 비트 수 만큼의 cyclic shift를 취하는 것이 있다. 예를 들어, 32비트 값 **00111**101100101101010100010101000에 5 비트 cyclic shift를 하면 왼쪽 5개 비트를 오른쪽으로 옮겨서 다음의 32비트 값 101100101101010100010101000**00111**이 나오게 된다. 이러한 연산은 산술적으로 볼 때 큰 의미가 없지만 비트를 다양하게 만든다는 목표는 충실히 이행한다. 파이썬에서 이러한 연산을 하기 위해서는 비트 연산 `<<`와 `>>`를 신중하게 이용하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hash_code(s):\n",
    "    mask = (1 << 32) - 1                   # limit to 32-bit integers\n",
    "    h = 0\n",
    "    for character in s:\n",
    "        h = (h << 5 & mask) | (h >> 27)    # 5-bit cyclic shift of running sum\n",
    "        h += ord(character)                # add in value of next character\n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전통적인 다항 해쉬 코드와 마찬가지로 cyclic-shift 해쉬 코드를 이용할 때에도 fine-tuning이 필요하다. 특히 쉬프트 연산의 크기를 결정해야 한다. 위에서 쉬프트의 크기를 5 비트로 한 것은 230000개가 넘는 영단어에 대한 실험을 통해 도출된 결과이다.\n",
    "\n",
    "<img width=\"200\" alt=\"table-10.1\" src=\"https://user-images.githubusercontent.com/20944657/36956084-aacde78a-206f-11e8-8d1d-81bd1afbc1c6.png\">\n",
    "\n",
    "\n",
    "### Hash Codes in Python\n",
    "파이썬에서 해쉬 코드를 계산하는 표준적인 메커니즘은 built-in 함수인 `hash(x)`를 이용하는 것이다. `hash(x)`는 객체 $x$에 대한 해쉬 코드를 반환한다. 그런데 파이썬에서는 오직 **immutable**한 자료형만 hashable하다고 취급한다. 이러한 제약은 객체가 존재하는 내내 해쉬 코드가 상수로 유지되게끔 하기 위한 것이다. 이는 객체를 해쉬 테이블의 key로 이용하기 위한 매우 중요한 성질이다. 만약 key가 해쉬 테이블에 추가되었는데 추가 됐을 때와 다른 해쉬 코드를 가진 key로 탐색을 한다고 하면, 잘못된 버켓을 찾게 될 것이다.\n",
    "\n",
    "파이썬의 built-in 자료 형 중에서도 immutable `int`, `float`, `str`, `tuple`, `frozenset` 클래스들은 `hash` 함수를 통해 robust한 해쉬 코드를 만들어낼 수 있다. `string`의 해쉬 코드는 `exclusive-or` 연산 대신 덧셈을 이용한다는 점을 빼면 앞서 다룬 다항 해쉬 코드와 비슷한 테크닉을 이용해서 만들 수 있다. 만약 위에서 제시했던 표와 비슷한 실험을 하면 230000개의 영단어에 대해 8개의 문자열만 서로와 충돌하게 된다. `tuple`의 해쉬코드는 튜플의 개별 원소의 해쉬 코드의 조합을 이용하는 비슷한 테크닉으로 계산할 수 있다. `frozenset`을 해쉬할 때는 원소에 순서가 없으므로 `shift` 없이 `exclusive-or`을 하는 것이 자연스럽다. `list`와 같이 mutable한 타입 `x`에 `hash(x)`를 호출하면 `TypeError`가 발생한다.\n",
    "\n",
    "사용자 정의 클래스의 인스턴스들은 기본적으로 unhashable로 취급되므로 `hash`를 호출하면 `TypeError`가 발생한다. 그러나 클래스 내의 `__hash__` 스페셜 메소드를 이용하면 해쉬코드를 계산하는 함수를 구현할 수 있다. 반환된 해쉬 코드는 인스턴스의 immutable한 attribute들을 반드시 반영해야 한다. 일반적으로는 그러한 attribute들을 조합해서 해쉬 값을 구한 후 그 해쉬 값에 기반해서 해쉬 코드를 반환한다. 예를 들어 3개의 수치 값 red, green, blue를 저장하는 `Color` 클래스의 `__hash__`는 다음과 같이 구현할 수 있다.\n",
    "\n",
    "```python\n",
    "def __hash__(self):\n",
    "    return hash((self._red, self._green, self._blue))  # hash combined tuple\n",
    "```\n",
    "\n",
    "이 때 중요한 규칙은 만약 클래스가 `__eq__`를 통해 클래스 동등성 비교를 지원하고 있다면 `__hash__` 함수의 구현도 일관성이 있어야 한다. 즉, `x == y`이면 `hash(x) == hash(y)`여야 한다. 이러한 규칙은 서로 다른 클래스의 객체들의 well-defined 비교에도 모두 확장되어야 한다. 예를 들어 파이썬이 `5 == 5.0`을 True라고 판단하므로 `hash(5)`와 `hash(5.0)`은 같아야 한다.\n",
    "\n",
    "### Compression Functions\n",
    "$k$의 해쉬 코드는 일반적으로 바로 버켓 배열에 쓰기에 적합하지 않은데, 정수 해쉬 코드는 음수일수도 있고 버켓 배열의 수용능력을 넘는 값일 수도 있기 때문이다. 따라서 $k$의 정수 해쉬 코드를 구한 다음에는 여전히 그 정수를 $[0, N-1]$ 범위 안으로 매핑하는 문제가 남는다. **압축 함수(compression function)**이라고 알려진 이 연산은 전체 해쉬 함수 안에서 실행되는 두 번째 동작이다. 좋은 압축 함수는 주어진 해쉬 코드의 집합을 이용해서 collision의 수를 최소화하는 함수이다.\n",
    "\n",
    "### The Division method\n",
    "간단한 압축 함수 중 하나는 **division method**이다. division method는 $N$이 버켓 배열의 크기일 때, 정수 $i$를 $i$ $mod$ $N$ 으로 매핑한다. 추가적으로, $N$을 소수(prime number)로 정한다면 이 압축 함수는 해쉬 값들의 분포가 \"퍼지게끔\" 도울 수 있다. 만약에 $N$이 소수가 아니라면 해쉬 코드의 분포에 나타나는 패턴이 반복되어 collision이 발생할 가능성이 있다. 예를 들어 해쉬 코드 {200, 205, 210, 215, 220, ..., 600}을 사이즈 100의 버켓 배열에 넣었다고 하자. 그러면 각각의 해쉬 코드는 3개의 값과 충돌하게 될 것이다. 그러나 만약 사이즈 101인 버켓 배열을 사용한다면 충돌이 나타나지 않을 것이다. 해쉬 함수를 잘 고른다면, 두 개의 서로 다른 key가 같은 버켓으로 해쉬될 가능성은 $1/N$이 된다. 그러나 $N$을 소수로 고르는 것만으로 항상 충분한 것은 아니다. 만약 해쉬 코드 안에 $pN + q$ 꼴의 패턴을 갖는 값들이 있다면 여전히 collision이 존재할 것이다.\n",
    "\n",
    "### The MAD Method\n",
    "정수 key의 반복적인 패턴을 제거해주는 더 복잡한 압축 함수는 **Multiply-Add-and-Divide** (or \"MAD\") 메소드이다. 이 메소드는 $N$이 버켓 배열의 사이즈이고, $p$가 $N$보다 큰 정수이며, $a \\gt 0$와 $b$가 구간 $[0, p-1]$에서 랜덤으로 뽑은 정수일 때, 정수 $i$를\n",
    "\n",
    "$[(ai + b)$ $mod$ $p]$ $mod$ $N$ 으로 매핑한다.\n",
    "\n",
    "이 압축 함수는 해쉬 코드의 집합에서 반복되는 패턴을 제거하고 더 \"좋은\" 해쉬 함수를 갖게끔, 즉 두 서로 다른 key가 충돌할 가능성이 $1/N$이게끔 선택되었다. 이는 $A$에 랜덤으로 uniform하게 key를 던질 경우와 같은 확률이다.\n",
    "\n",
    "### 10.2.2 Collision-Handling Schemes\n",
    "해쉬 테이블의 주된 아이디어는 버켓 배열 $A$와 해쉬 함수 $h$를 이용해서 각각의 항목 (k,v)를 버켓 $A[h(k)]$에 저장하는 것이다. 그러나 만약 두 서로 다른 key $k_{1}$, $k_{2}$에 대해서 $h(k_{1}) = h(k_{2})$이면 이러한 아이디어에 문제가 생긴다. 이러한 **충돌(collision)**이 존재하면 새로운 항목 (k,v)를 바로 $A[h(k)]$에 저장하는 것이 불가능하다. 또, 추가, 탐색, 삭제 연산을 실행하는 것도 복잡해진다.\n",
    "\n",
    "### Seperate Chaining\n",
    "이러한 collision을 다루는 단순하고 효율적인 방법은 각각의 버켓 $A[j]$가 $h(k) = j$인 (k,v) 항목들을 저장하는 보조적인 컨테이너를 저장하게끔 하는 것이다. 우리는 Section 10.1.5에서 설명했던 것처럼 리스트를 이용해 작은 맵 인스턴스를 구현할 수 있다. 이러한 **collision resolution** rule은 **seperate chaining**이라고 알려져 있고, 아래의 그림과 같다\n",
    "\n",
    "<img width=\"500\" alt=\"figure-10.6\" src=\"https://user-images.githubusercontent.com/20944657/36959314-b8d43cb6-2084-11e8-8f7a-e3e659496a92.png\">\n",
    "\n",
    "최악의 경우, 각각의 버켓에 대한 연산은 버켓의 사이즈에 의존한다. $N$개의 버켓 배열에 $n$개의 원소를 인덱스해주는 좋은 해쉬 함수를 사용한다고 가정하면 버켓의 예상 사이즈는 $n/N$이다. 그러면 이 때 핵심적인 맵 연산들은 $O(\\lceil n/N \\rceil)$ 시간 안에 끝난다. 이 때의 비율 $\\lambda = n/N$을 해쉬 테이블의 **load factor**라고 하고, 1보다 작은 상수보다 작게 유지한다. $\\lambda$가 $O(1)$이기만 하면 해쉬 테이블의 핵심적인 연산은 모두 $O(1)$ 예상 시간 복잡도를 갖게 된다.\n",
    "\n",
    "### Open Addressing\n",
    "seperate chaining 룰은 맵 연산에 대한 단순한 구현을 제공하는 등 많은 좋은 성질들을 갖고 있지만 그럼에도 불구하고 하나의 작은 단점을 갖는다. 그 단점은 바로 충돌하는(colliding) key의 항목들을 저장하기 위한 보조적인 자료 구조(리스트)의 이용을 필요로 한다는 점이다. 메모리 공간을 절약하는 것이 중요한 환경(예를 들어, 초소형 기기를 위한 프로그램을 만드는 경우)이라면 항상 모든 항목을 테이블의 슬롯에 직접 저장하는 대안을 이용할 수 있다. 이러한 접근방식은 보조적인 자료 구조의 필요가 없으므로 많은 공간을 절약할 수 있다. 그러나 collision을 다루기 위해 더 복잡한 처리를 해줘야 한다. 이러한 접근방식에는 여러 변형이 있고 이들은 모두 **open addressing**이라 불리고, 이후에 논의할 것이다. Open addressing을 이용할 때는 로드 팩터가 항상 1보다 작아야 하고, 항목들이 버켓 배열에 직접 저장되어야 한다.\n",
    "\n",
    "### Linear Probing and Its Variants\n",
    "open addressing을 이용해서 collision을 다루는 간단한 방법은 **linear probing**이다. 이 방법에 따르면 만약 이미 꽉 차있는 버켓 $A[j]$에 (k,v)를 추가하려고 하는 경우, 예를 들어 $j=h(k)$인 경우가 생기면 그 대신 A[($j + 1$) mod $N$]에 원소를 추가한다. 만약 A[($j + 1$) mod $N$]도 이미 차있다면 A[($j + 2$) mod $N$]를 이용해본다. 이렇게 해서 빈 버켓을 찾을때까지 계속해서 반복한다. 그렇게 해서 빈 버켓을 찾은 경우 이 버켓에 새로운 항목을 저장한다. 물론, 이러한 collision resolution 전략을 쓰려면 key를 탐색하는 부분을 변경해줘야 한다. 예를 들어 `__getitem__`, `__setitem__`, `__delitem__` 연산자의 첫 부분은 모두 변경해줘야 한다. $k$와 같은 키를 갖는 항목을 찾기 위해서 우리는 A[$h(k)$]부터 시작해서 원하는 값을 찾거나 빈 버켓을 만날때까지 연속적으로 탐색을 해야한다. \"linear probing\"이라는 이름은 버켓 배열의 셀에 접근하는 것이 마치 \"탐색, 조사(probe)\"하는 것과 같다는 사실에서 지어진 이름이다.\n",
    "\n",
    "<img width=\"600\" alt=\"figure-10.7\" src=\"https://user-images.githubusercontent.com/20944657/36960200-3ae98900-2089-11e8-8c84-9d8d0c75c444.png\">\n",
    "\n",
    "이제 추가가 아닌 삭제를 생각해보자. 우리는 배열의 슬롯에서 찾은 항목을 단순히 제거할 수 없다. 예를 들어, 위에서처럼 key 15를 추가한 다음 37이 제거되었다고 하자. 그러면 이제 15를 찾는 것이 불가능해지는데, 인덱스 4와 5를 탐색한 후의 인덱스인 인덱스 6이 비어있기 때문에 탐색이 끝나기 때문이다. 이러한 문제점을 우회하는 일반적인 방법은 삭제된 항목을 \"available\" 이라는 특별한 마커 객체로 교체하는 것이다. 이 경우 우리는 우리의 탐색 알고리즘이 마커를 만나면 그냥 무시하고 탐색을 계속하게끔 해서 원하는 항목을 찾거나, 빈 슬롯을 만나게끔 할 수 있다. 추가적으로, `__setitem__` 알고리즘은 이 마커 객체가 있던 셀을 기억해야 하는데, 만약 원하던 항목을 찾지 못했다면 이 마커가 있던 셀에 새로운 항목을 추가해야 하기 때문이다.\n",
    "\n",
    "open addressing이 공간을 절약해주긴 하지만 linear probing에도 단점이 있다. linear probing을 이용하게 되면 맵의 항목들을 연속적으로 배치하게 되어 항목들의 클러스터링이 발생한다. 이렇게 되면 서로 다른 key를 가진 항목들이 겹치게 될 수 있어 탐색이 심각하게 느려질 수 있다.\n",
    "\n",
    "이러한 문제를 회피하는 또 다른 open addressing 전략은 **quadratic probing**이 있다. quadratic probing은 만약 셀이 이미 차있을 경우 한 칸 뒤의 슬롯을 이용하는 것이 아니라 빈 버켓을 만날 때까지 버켓 A[($h(k)+f(i)$)], $f(i)=i^{2}$를 이용한다. linear probing에서 그랬듯이 quadratic probing 또한 제거 연산을 어렵게 한다. 그러나 quadratic probing을 이용하면 linear probing에서 발생하는 클러스터링 문제를 회피할 수 있다. 그럼에도 불구하고 quadratic probing에서도 **secondary clustering**이라 불리는 클러스터링 문제가 생기는데, 이는 해쉬 코드가 uniform하게 분포되어있다고 가정했음에도 원소를 포함하는 배열 셀들의 분포가 uniform하지 않은 패턴을 갖게 되는 문제이다. $N$이 소수이고 버켓 배열이 반 이하로 차 있다면 quadratic probing 전략은 빈 슬롯을 찾을 수 있음을 보장한다. 그러나 만약 테이블이 반 이상 차거나 $N$이 소수가 아니라면 이러한 보장이 깨지게 된다.(Exercise C-10.36)\n",
    "\n",
    "linear probing이나 quadratic probing에서 발생하는 클러스터링 문제를 피할 수 있는 open addressing 전략을 **double hashing** 전략이라 한다. 이 접근방식에서는 보조 해쉬 함수 $h^{'}$를 선택한다. 만약 $h$가 이미 어떤 key $k$를 점유된 버켓 A[$h(k)$]로 매핑한다면 우리는 그 다음으로 A[$(h(k) + f(i))$ mod $N$], where $f(i) = i \\cdot h^{'}(k)$를 이용한다. 이러한 방식에서는 보조 해쉬 함수 $h^{i}$의 값이 0이면 안된다. 일반적으로는 $q \\lt N$인 소수 $q$에 대해 $h^{'}(k) = q - (k$ mod $q)$이게끔 $h^{'}$를 정의한다. 이 때 $N$은 반드시 소수여야 한다.\n",
    "\n",
    "open addressing의 클러스터링을 피하기 위한 또 다른 방법으로는 A[$(h(k)+f(i))$ mod $N$], where $f(i)$ is psuedo-random number generator 를 이용하는 방법이 있다. 이러한 방법을 이용하면 해쉬 코드의 비트를 이용하면서, 반복되면서도 랜덤의 성격을 갖는 탐색 시퀀스를 얻을 수 있다. 이 방식은 파이썬 딕셔너리 클래스가 이용하고 있는 방식이다.\n",
    "\n",
    "### 10.2.3 Load Factors, Rehashing, and Efficiency\n",
    "지금까지 설명한 해쉬 테이블에 따르면 로드 팩터 $\\lambda = n/N$을 항상 1보다 낮게 유지하는 것이 중요하다. seperate chaining에서는 $\\lambda$가 1에 가까워질수록 collision의 확률이 크게 증가하고, $O(n)$의 시간이 걸리는 리스트 기반 메소드를 이용할 확률이 높아지므로 우리의 연산에 큰 오버헤드가 걸린다. 실험과 평균 분석에 따르면 우리는 seperate chaining을 이용할 때 항상 $\\lambda \\lt 0.9$를 유지해야 한다.\n",
    "\n",
    "또한 open addressing에서는 로드 팩터 $\\lambda$가 0.5를 넘어 1에 가까워질수록 버켓 배열의 클러스터가 점점 확대된다. 이렇게 클러스터가 커지면 probing 과정에서 빈 슬롯을 찾기 위한 탐색에 드는 시간이 점점 많아진다. linear probing에서는 항상 $\\lambda \\lt 0.5$를 유지해줘야 하고, 다른 probing 방식에서는 그보다 조금 더 높은 $\\lambda$ 값을 허용한다. 예를 들어 파이썬의 open addressing 구현은 $\\lambda \\lt 2/3$을 요구한다.\n",
    "\n",
    "만약 항목의 추가가 로드 팩터를 1보다 크게 만드는 경우 일반적으로 다시 로드 팩터를 낮추기 위해 테이블을 리사이징하고 모든 객체들을 이 새로운 객체에 다시 추가한다. 이 경우 각각의 객체에 대한 새로운 해쉬 코드를 정의할 필요는 없지만 새로운 테이블의 크기를 고려한 새로운 압축 함수를 적용해야 한다. 각각의 **rehashing**은 일반적으로 새로운 버켓 배열에 항목들을 흩뿌려놓는다. 새로운 테이블로 rehashing을 할 때는 새로운 배열의 크기가 적어도 지난번보다 2배 이상 큰 게 바람직하다. 실제로 만약 우리가 rehasing할 때마다 배열의 크기를 두배로 만든다면 테이블의 모든 항목을 rehashing하기 위한 비용을 amortize할 수 있다(as with dynamic arrays; See Section 5.3).\n",
    "\n",
    "### Efficiency of Hash Tables\n",
    "hashing의 average-case 분석에 대한 디테일은 이 책의 범위가 아니지만, 그 확률론적 기초는 꽤나 직관적이다. 만약 우리의 해쉬 함수가 좋다면(good), 우리는 항목들이 버켓 배열의 $N$개 셀에 균등 분포될 것을 기대한다. 따라서 $n$개의 항목을 저장하는 경우 버켓 안의 예상되는 key의 수는 $\\lceil \\dfrac{n}{N} \\rceil$이 되고, $n$이 $O(N)$인 경우 $O(1)$이 된다.\n",
    "\n",
    "추가나 삭제 이후 테이블을 리사이즈할 때 발생하는 rehashing과 관련된 비용은 `__setitem__`과 `__getitem__`에 추가적인 $O(1)$ amortized cost를 부과한다. 최악의 경우, 좋지 않은(poor) 해쉬 함수는 모든 항목을 같은 버켓으로 매핑할 것이다. 이렇게 되면 seperate chaining이나 open addressing 모델에서 핵심적인 맵 연산들의 연산들이 $O(n)$ 시간 복잡도를 갖게 될 것이다. 아래의 표는 맵을 unsorted list로 구현했을 때와 해쉬 테이블을 이용했을 때 핵심 연산들의 시간 복잡도를 나타낸 것이다.\n",
    "\n",
    "<img width=\"400\" alt=\"table-10.2\" src=\"https://user-images.githubusercontent.com/20944657/36961940-d7addb54-2090-11e8-8aa4-605d222d3c5c.png\">\n",
    "\n",
    "현실에서는 해쉬 테이블이 맵을 구현하는 가장 효율적인 방법 중 하나이고, 프로그래머들은 해쉬 테이블을 이용했을 때 핵심적인 연산들이 상수 시간 안에 이루어진다는 것을 당연하게 여기고 있다. 파이썬 `dict` 클래스는 해쉬로 구현되어 있고, 파이썬 인터프리터는 식별자에 의해 참조되는 객체를 네임스페이스에서 찾고자 할때 딕셔너리를 이용한다. 기본적인 명령어인 `c = a + b`는 로컬 네임스페이스의 딕셔너리에 대해 `__getitem__`을 두 번 호출해서 `a`와 `b`에 의해 식별되는 값을 받아온다. 앞으로의 알고리즘 분석에서는 딕셔너리의 연산들이 네임 스페이스의 항목 수에 관계 없이 항상 상수 시간 안에 실행된다고 가정한다.\n",
    "\n",
    "2003년에 나온 한 논문에서는 연구자들이 해쉬 테이블의 worst-time 퍼포먼스를 이용해서 DoS(denial-of-service) 공격이 가능할 수 있다는 주장을 하기도 했다. 해쉬 코드를 계산하는 알고리즘들에 대해서 그 해쉬 값을 계산했을 때 모두 같은 32비트 해쉬 코드 값을 갖는 문자열들을 미리 계산해두면 공격이 가능하다는 것이다.(지금까지 설명한 해쉬 scheme 중에서 double hashing을 제외하면, 만약 두 key가 같은 해쉬 코드 값을 가질 경우 collision resolution에서 이 둘을 분리할 수 있는 것은 없다. 이게 무슨 말이냐 하면, double hashing의 경우 두 key $k_{1}$, $k_{2}$에 대해 $h(k_{1}) = h(k_{2})$이더라도 $h^{'}(k) = q - (k$ mod $q)$에서 $k$ 값에 따라 두 key의 경로가 달라진다. 그러나 다른 방법에서는 두 key의 경로가 일치하게 된다)\n",
    "\n",
    "그리고 2011년 말에 다른 연구진들이 논문에서 위의 공격을 실제로 구현했다. 웹 서버들은 URL 안에 key-value 파라미터들을 연속적으로 입력을 받는다. 예를 들어 `?key1=val1&key2=val2&key3=val3`과 같다. 일반적으로 이러한 key-value 페어는 서버에서 맵으로 저장되고, 맵의 저장 시간은 항목의 개수와 선형 관계를 가질 거라는 가정 하에 일반적으로 파라미터의 수와 길이에 제한을 둔다. 만약 모든 키가 충돌한다면 그 저장 시간은 quadratic해지고 서버에 과부하가 걸리게 된다. 2012년 봄, 파이썬 개발자들은 문자열의 해쉬 코드 계산에 랜덤성을 부여하는 보안 패치를 배포해서 리버스 엔지니어들이 충돌하는 문자열을 찾기 어렵게 했다. \n",
    "\n",
    "### 10.2.4 Python Hash Table Implementation\n",
    "이번 섹션에서는 seperate chaining과 linear probing을 이용한 open addressing을 이용해서 해쉬 테이블의 두 가지 구현을 제공한다. collision resolution을 위한 접근 방식이 크게 다르긴 하지만 이 두 해쉬 알고리즘에는 많은 공통점이 있다. 그러한 이유로 우리는 `MapBase` 클래스를 확장해서, 이 두 해쉬 테이블이 제공해야 할 공통적인 기능을 구현하는 `HashMapBase` 클래스를 정의할 것이다. `HashMapBase` 클래스의 주요 설계는 다음과 같다:\n",
    "\n",
    "- 버켓 배열은 `self._table`이라는 이름의 파이썬 리스트로 표현되며, 모든 항목은 None으로 초기화된다.\n",
    "- 해쉬 테이블 안에 저장된 개별적인 항목의 수를 나타내는 인스턴스 변수 `self._n`를 유지한다.\n",
    "- 테이블의 로드 팩터가 0.5 이상이 되는 경우 테이블의 크기를 두배로 늘리고 모든 항목들을 새로운 테이블로 rehash한다.\n",
    "- 파이썬 built-in `hash` 함수를 이용하는 `_hash_function` 유틸리티 메소드를 정의해서 key를 위한 해쉬 코드를 만들고 압축 함수(compression function)으로는 랜덤화된 MAD 공식을 이용한다.\n",
    "\n",
    "기초 클래스에서는 \"버켓\"이 어떻게 표현되어야 하는가에 대해서는 전혀 다루지 않는다. seperate chaining에서는 각각의 버켓이 독립적인 구조를 가질 것이지만 open addressing에서는 각각의 버켓을 위한 컨테이너가 존재하지 않고, \"버켓\"들은 probing sequences로 인해 효과적으로 엮일 것이다(interweaved). 우리의 설계에서 `HashMapBase` 클래스는 다음의 메소드들을 추상 메소드로 정의해서 구상 서브클래스들에 의해 구현되게 할 것이다.\n",
    "\n",
    "- `_bucket_getitem(j,k)`<br> 이 메소드는 버켓 $j$에서 key $k$를 갖는 항목을 찾아서 반환해야 한다. 만약 찾지 못하면 `KeyError`가 발생한다.\n",
    "\n",
    "\n",
    "- `_bucket_setitem(j,k,v)`<br> 이 메소드는 버켓 `j`를 수정해서 key `k`가 값 `v`와 연결되게끔 해야한다. 만약 그러한 key가 이미 존재하면 새로운 값이 이전의 값을 대체한다. 그렇지 않다면 새로운 항목이 추가되고, *이 메소드는 `self._n`을 증가시켜야 한다.*\n",
    "\n",
    "\n",
    "- `_bucket_delitem(j,k)`<br> 이 메소드는 버켓 `j`에서 key `k`를 갖는 항목을 제거해야 한다. 만약 그런 항목이 없다면 `KeyError`를 반환한다. 이 메소드 *이후*에는 `self._n`이 감소한다.\n",
    "\n",
    "\n",
    "- `__iter__`<br> 이 메소드는 맵의 모든 키를 순회하기 위한 표준적인 맵 메소드이다. 우리의 기초 클래스는 이를 버켓을 기반으로 하게끔 하지 않는데, open addressing에서의 \"버켓\"들은 disjoint하지 않을 수 있기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HashMapBase(MapBase):\n",
    "    \"\"\"Abstract base class for map using hash-table with MAD compression.\"\"\"\n",
    "    \n",
    "    def __init__(self, cap=11, p=109345121):\n",
    "        \"\"\"Create an empty hash-table map.\"\"\"\n",
    "        self._table = cap * [None]\n",
    "        self._n = 0\n",
    "        self._prime = p\n",
    "        self._scale = 1 + randrange(p-1)\n",
    "        self._shift = randrange(p)\n",
    "        \n",
    "    def _hash_function(self, k):\n",
    "        return (hash(k)*self._scale + self._shift) % self._prime % len(self._table)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._n\n",
    "    \n",
    "    def __getitem__(self, k):\n",
    "        j = self._hash_function(k)\n",
    "        return self._bucket_getitem(j,k)                  # may raise KeyError\n",
    "    \n",
    "    def __setitem__(self, k, v):\n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_setitem(j,k,v)                       # subroutine maintains self._n\n",
    "        if self._n > len(self._table) // 2:               # keep load factor <= 0.5\n",
    "            self._resize(2 * len(self._table) - 1)        # number 2^x -1 is often prime\n",
    "    \n",
    "    def __delitem__(self,k):     \n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_delitem(j,k)                         # may raise KeyError\n",
    "        self._n -= 1\n",
    "        \n",
    "    def _resize(self, c):                   # resize bucket array to capacity c\n",
    "        old = list(self.items())            # use iteration to record existing items\n",
    "        self._table = c * [None]            # then reset table to desired capacity\n",
    "        self._n = 0                         # n recomputed during subsequent adds\n",
    "        for (k,v) in old:\n",
    "            self[k] = v                     # reinsert old key-value pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate Chaining\n",
    "이제 seperate chain을 이용해서 해쉬 테이블에 대한 구체적인 구현을 제공하는 `ChainHashMap` 클래스를 보자. 우리는 각각의 버켓을 나타내기 위해서 앞서 정의했던 `UnsortedTableMap` 클래스의 인스턴스를 이용할 것이다. 클래스의 처음 세 메소드는 인덱스 $j$를 이용해서 버켓 배열의 버켓에 접근(access)하고, 만약 그 테이블의 엔트리가 `None`인지를 체크한다. 우리가 새로운 버켓 구조를 필요로 할 때는 비어있는 슬롯에 `_bucket_setitem`이 호출되었을 때 뿐이다. 남아있는 기능은 이미 `UnsortedTableMap` 인스턴스에 의해 지원되는 맵 동작들에 의존한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ChainHashMap(HashMapBase):\n",
    "    \"\"\"Hash map implemented with separate chaining for collision resolution.\"\"\"\n",
    "    \n",
    "    def _bucket_getitem(self, j, k):\n",
    "        bucket = self._table[j]\n",
    "        if bucket is None:\n",
    "            raise KeyError('Key Error: ' + repr(k))       # no match found\n",
    "        return bucket[k]                                  # may raise KeyError\n",
    "    \n",
    "    def _bucket_setitem(self, j, k, v):\n",
    "        if self._table[j] is None:\n",
    "            self._table[j] = UnsortedTableMap()           # bucket is new to the table\n",
    "        oldsize = len(self._table[j])\n",
    "        self._table[j][k] = v\n",
    "        if len(self._table[j]) > oldsize:                 # key was new to the table\n",
    "            self._n += 1                                  # increase overall map size\n",
    "            \n",
    "    def _bucket_delitem(self, j, k):\n",
    "        bucket = self._table[j]\n",
    "        if bucket is None:\n",
    "            raise KeyError('Key Error: ' + repr(k))       # no match found\n",
    "        del bucket[k]                                     # may raise KeyError\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for bucket in self._table:\n",
    "            if bucket is not None:                        # a nonempty slot\n",
    "                for key in bucket:\n",
    "                    yield key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Probing\n",
    "이제 linear probing을 이용한 open addressing을 통해 해쉬 테이블을 구현한 `ProbeHashMap` 클래스를 구현해보자. 삭제 연산을 지원하기 위해 삭제된 테이블의 위치에 특별한 마커를 두는 테크닉을 이용할 것이다. 이렇게 하면 비어있던 위치와 원래 항목이 있다가 삭제된 위치를 구분하는 것이 가능해진다. 우리의 구현에서는 클래스 attribute인 `_AVAIL`을 센티널로 선언할 것이다. 이때 우리는 센티널의 동작에는 관심이 없고 다른 객체와 구분하는 데에만 관심이 있으므로 built-in `object` 클래스의 인스턴스를 이용했다. open addressing의 가장 어려운 부분은 항목의 추가나 탐색 과정에서 collision이 일어날 경우 탐색 과정을 잘 추적하는 일이다. 이를 위해서 우리는 nonpublic 유틸리티 메소드인 `_find_slot`을 정의해서 \"버켓\" $j$에서 key $k$를 갖는 항목을 찾게 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ProbeHashMap(HashMapBase):\n",
    "    \"\"\"Hash map implemented with linear probing for collision resolution.\"\"\"\n",
    "    _AVAIL = object()      # sentinel marks locations of previous deletions\n",
    "    \n",
    "    def _is_available(self, j):\n",
    "        \"\"\"Return True if index j is available in table.\"\"\"\n",
    "        return self._table[j] is None or self._table[j] is ProbeHashMap._AVAIL\n",
    "    \n",
    "    def _find_slot(self, j, k):\n",
    "        \"\"\"Search for key k in bucket at index j.\n",
    "        \n",
    "        Return (success, index) tuple, described as follows:\n",
    "        If match was found, success is True and index denotes its location.\n",
    "        If no match found, success is False and index denotes first available slot.\n",
    "        \"\"\"\n",
    "        firstAvail = None\n",
    "        while True:\n",
    "            if self._is_available(j):\n",
    "                if firstAvail is None:\n",
    "                    firstAvail = j                    # mark this as first avail\n",
    "                if self._table[j] is None:\n",
    "                    return (False, firstAvail)        # search has failed\n",
    "            elif k == self._table[j]._key:\n",
    "                return (True, j)                      # found a match\n",
    "            j = (j + 1) % len(self._table)            # keep looking (cyclically)\n",
    "            \n",
    "    def _bucket_getitem(self, j, k):\n",
    "        found, s = self._find_slot(j, k)\n",
    "        if not found:\n",
    "            raise KeyError('Key Error: ' + repr(k))   # no match found\n",
    "        return self._table[s]._value\n",
    "    \n",
    "    def _bucket_setitem(self, j, k, v):\n",
    "        found, s = self._find_slot(j, k)\n",
    "        if not found:\n",
    "            self._table[s] = self._Item(k,v)\n",
    "            self._n += 1\n",
    "        else:\n",
    "            self._table[s]._value = v\n",
    "            \n",
    "    def _bucket_delitem(self, j, k):\n",
    "        found, s = self._find_slot(j,k)\n",
    "        if not found:\n",
    "            raise KeyError('Key Error: ' + repr(k))\n",
    "        self._table[s] = ProbeHashMap._AVAIL\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for j in range(len(self._table)):             # scan entire table\n",
    "            if not self._is_available(j):\n",
    "                yield self._table[j]._key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3 Sorted Maps\n",
    "전통적인 맵 ADT는 유저가 key를 이용해서 값을 찾는 것을 허용하지만, 그 key의 탐색은 **exact search**라고 알려진 형태를 취한다. 예를 들어 컴퓨터 시스템은 일어난 사건들에 대한 정보(e.g., 금융 거래내역)를 저장하는데, **타임 스탬프(time stamp)**라고 알려진 것에 따라 이 사건들을 정리한다. 만약 특정 시스템에서 타임 스탬프가 유니크하다는 것을 가정한다면 우리는 타임 스탬프를 key로 하고, 그 시간에 일어난 사건을 value로 하는 맵을 만들 수 있다. 특정한 타임 스탬프는 사건을 위한 참조 ID로 쓰일 수 있고, 이 경우 우리는 맵에서 그 사건에 대한 정보를 빠르게 얻어낼 수 있다. 하지만 맵 ADT는 모든 사건을 시간 순서대로 정리한 리스트를 얻을 수 있는 어떠한 방법도 제공하지 않으며, 특정 시간에 가장 가까운 사건을 찾는 것도 불가능하다. 사실 맵 ADT의 해쉬 기반 구현의 빠른 성능은 원래의 도메인에서는 굉장히 \"가깝게\" 보이는 key들을 고의적으로 흐트려놓는 방법을 통해 해쉬 테이블 내에서 이 key들이 균등 분포를 갖게끔 하기에 가능한 것이다.\n",
    "\n",
    "이번 섹션에서는 **sorted map** ADT라 알려진 맵 ADT의 확장을 다룬다. 이 sorted map ADT는 표준적인 맵의 모든 동작을 포함하면서도 다음의 동작들을 지원한다:\n",
    "- **M.find_min():** 최소 키를 가진 (key,value) 페어를 반환한다(맵이 비어있으면 None을 반환한다).\n",
    "- **M.find_max():** 최대 키를 가진 (key,value) 페어를 반환한다(맵이 비어있으면 None을 반환한다).\n",
    "- **M.find_lt(k):** $k$보다 작으면서 가장 큰 키를 가진 (key,value) 페어를 반환한다(그런 항목이 없으면 None을 반환한다).\n",
    "- **M.find_le(k):** $k$보다 작거나 같으면서 가장 큰 키를 가진 (key,value) 페어를 반환한다(그런 항목이 없으면 None을 반환한다).\n",
    "- **M.find_gt(k):** $k$보다 크면서 가장 작은 키를 가진 (key,value) 페어를 반환한다(그런 항목이 없으면 None을 반환한다).\n",
    "- **M.find_ge(k):** $k$보다 크거나 같으면서 가장 작은 키를 가진 (key,value) 페어를 반환한다(그런 항목이 없으면 None을 반환한다).\n",
    "- **M.find_range(start, stop):** start $\\leq$ key $\\leq$인 모든 (key, value)를 순회한다. 만약 start가 None이면 iteration이 가장 작은 키에서 시작한다. 만약 stop이 None이면 iteration이 가장 높은 키에서 끝난다.\n",
    "- **iter(M):** key의 자연스러운 순서에 따라서 작은 key부터 큰 key까지 모든 key를 순회한다.\n",
    "- **reversed(M):** 맵의 모든 key를 역순으로 순회한다. 파이썬에서 이 메소드는 `__reversed__` 메소드로 구현된다.\n",
    "\n",
    "### 10.3.1 Sorted Search Tables\n",
    "여러 자료 구조가 sorted map ADT를 효율적으로 지원할 수 있고, 그 중 몇몇 고급 테크닉을 Section 10.4와 Chapter 11에서 볼 것이다. 이번 섹션에서는 sorted map의 간단한 구현을 알아볼 것이다. 우리는 맵의 항목들을 배열 기반의 시퀀스인 $A$에 저장해서 그 항목들이 key의 오름차순으로 정렬되게끔 할 것이다. 이 때 key는 자연스럽게 순서가 정의된다고 가정한다. 이러한 맵의 구현을 **sorted search table**이라 한다.\n",
    "\n",
    "<img width=\"600\" alt=\"figure-10.8\" src=\"https://user-images.githubusercontent.com/20944657/36970643-99ea610e-20ac-11e8-950d-dfbf726ff782.png\">\n",
    "\n",
    "Section 10.1.5의 unsorted table map이 그랬듯이 sorted search table은 맵의 항목 수에 따라 배열을 늘리고 줄이기 때문에 공간 복잡도가 $O(n)$이다. 이 표현 방식의 가장 큰 장점이자 우리가 $A$를 배열로 가장 큰 이유는 이렇게 함으로써 효율적인 연산을 위해 **바이너리 서치(binary search)** 알고리즘을 사용할 수 있게 된다는 것이다. \n",
    "\n",
    "### Binary Search and Inexact Searches\n",
    "Section 4.1.3에서 정렬된 시퀀스 안에서 특정 값을 찾는 바이너리 서치 알고리즘을 설명한 적이 있다. 그 때는 특정 값이 있는지 없는지를 확인하고 True나 False 값을 반환했다. 이러한 접근방식을 이용하면 맵 ADT의 `__contains__` 메소드를 구현할 수 있다. 여기서 더 나아가면, 바이너리 서치를 이용한 부정확한 서치를 이용해서 더 많은 정보를 제공하는 것이 가능하다. 이는 sorted map ADT를 구현할 때 굉장히 유용하다. 이 때 중요한 사실은, 바이너리 서치를 실행할 때 우리는 타겟 값이 위치하는 인덱스나 그 근처의 인덱스를 찾을 수 있다는 점이다. 조금 더 자세히 말하자면, 탐색이 성공할 경우에는 타겟 값의 인덱스를 찾을 수 있고, 탐색이 실패해서 타겟 값을 찾지 못한 경우에도 타겟 값보다 조금 크거나 작은 원소들을 가리키는 인덱스의 페어를 효과적으로 찾을 수 있다.\n",
    "\n",
    "<img width=\"600\" alt=\"figure-4.5\" src=\"https://user-images.githubusercontent.com/20944657/36972837-04c813de-20b4-11e8-875f-40b0904ba949.png\">\n",
    "\n",
    "예를 들어 위의 바이너리 서치 과정을 생각해보자. 위에서는 22를 찾고 있었지만 만약 21을 찾고 있었다면 처음 네번의 스텝은 같지만, 마지막에 `high=9`, `low=10`으로 `high`와 `low`가 역전된 채로 호출이 이루어질 것이고, 이는 우리가 찾고자 했던 타겟 값이 19와 22 사이에 있는 값이라는 정보를 주게 된다.\n",
    "\n",
    "### Implementation\n",
    "이제 우리는 sorted map ADT를 지원하는 `SortedTableMap` 클래스에 대한 코드를 제공할 것이다. 자세한 설명은 생략한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SortedTableMap(MapBase):\n",
    "    \"\"\"Map implementation using a sorted table.\"\"\"\n",
    "    \n",
    "    #--------------------- nonpublic behaviors --------------------\n",
    "    def _find_index(self, k, low, high):\n",
    "        \"\"\"Return index of the leftmost item with key greater than or equal to k.\n",
    "        \n",
    "        Return high + 1 if no such item qualifies\n",
    "        \n",
    "        That is, j will be returned such that:\n",
    "            all items of slice table[low:j] have key < k\n",
    "            all items of slice table[j:high+1] have key >= k\n",
    "        \"\"\"\n",
    "        if high < low:                                         # no element qualifies\n",
    "            return high + 1\n",
    "        else:\n",
    "            mid = (low + high) // 2\n",
    "            if k == self._table[mid]._key:\n",
    "                return mid                                     # found exact match\n",
    "            elif k < self._table[mid]._key:\n",
    "                return self._find_index(k, low, mid - 1)       # Note: may return mid\n",
    "            else:\n",
    "                return self._find_index(k, mid+1, high)        # answer is right of mid\n",
    "            \n",
    "    #----------------------- public behaviors ----------------------\n",
    "    def __init__(self):\n",
    "        \"\"\"Create an empty map.\"\"\"\n",
    "        self._table = []\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Return number of items in the map.\"\"\"\n",
    "        return len(self._table)\n",
    "    \n",
    "    def __getitem__(self, k):\n",
    "        \"\"\"Return value associated with key k (raise KeyError if not found).\"\"\"\n",
    "        j = self._find_index(k, 0, len(self._table) - 1)\n",
    "        if j == len(self._table) or self._table[j]._key != k:\n",
    "            raise KeyError('Key Error: ' + repr(k))\n",
    "        return self._table[j]._value\n",
    "        \n",
    "    def __setitem__(self, k, v):\n",
    "        \"\"\"Assign value v to key k, overwriting existing value if present.\"\"\"\n",
    "        j = self._find_index(k, 0, len(self._table) - 1)\n",
    "        if j < len(self._table) and self._table[j]._key == k:\n",
    "            self._table[j]._value = v                            # reassign value\n",
    "        else:\n",
    "            self._table.insert(j, self._Item(k,v))               # adds new item\n",
    "        \n",
    "    def __delitem__(self, k):\n",
    "        \"\"\"Remove item associated with key k (raise KeyError if not found).\"\"\"\n",
    "        j = self._find_index(k, 0, len(self._table) - 1)\n",
    "        if j == len(self._table) or self._table[j]._key != k:\n",
    "            raise KeyError('Key Error: ' + repr(k))\n",
    "        self._table.pop(j)                                       # delete item\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Generate keys of the map ordered from minimum to maximum.\"\"\"\n",
    "        for item in self._table:\n",
    "            yield item._key\n",
    "    \n",
    "    def __reversed__(self):\n",
    "        for item in reversed(self._table):\n",
    "            yield item._key\n",
    "            \n",
    "    def find_min(self):\n",
    "        \"\"\"Return (key, value) pair with minimum key (or None if empty).\"\"\"\n",
    "        if len(self._table) > 0:\n",
    "            return (self._table[0]._key, self._table[0]._value)\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def find_max(self):\n",
    "        \"\"\"Return (key, value) pair with maximum key (or None if empty).\"\"\"\n",
    "        if len(self._table) > 0:\n",
    "            return (self._table[-1]._key, self._table[-1]._value)\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def find_ge(self, k):\n",
    "        \"\"\"Return (key, value) pair with least key greater than or equal to k.\"\"\"\n",
    "        j = self._find_index(k, 0, len(self._table) - 1)             # j's key >= k\n",
    "        if j < len(self._table):\n",
    "            return (self._table[j]._key, self._table[j]._value)\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    # This might be wrong implementation.. .. . .\n",
    "    def find_le(self, k):\n",
    "        \"\"\"Return (key, value) pair with greatest key lower than or equal to k.\"\"\"\n",
    "        j = self._find_index(k, 0, len(self._table) - 1)             # j's key >= k\n",
    "        if j < len(self._table) and self._table[j]._key == k:\n",
    "            return (self._table[j]._key, self._table[j]._value)\n",
    "        if j > 0:\n",
    "            return (self._table[j-1]._key, self._table[j-1]._value)\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def find_lt(self, k):\n",
    "        \"\"\"Return (key, value) pair with greatest key strictly less than k.\"\"\"\n",
    "        j = self._find_index(k, 0, len(self._table) - 1)             # j's key >= k\n",
    "        if j > 0:\n",
    "            return (self._table[j-1]._key, self._table[j-1]._value)  # note use of j-1\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def find_gt(self, k):\n",
    "        \"\"\"Return (key, value) pair with least key strictly greater than k.\"\"\"\n",
    "        j = self._find_index(k, 0, len(self._table) - 1)             # j's key >= k\n",
    "        if j < len(self._table) and self._table[j]._key == k:\n",
    "            j += 1\n",
    "        if j < len(self._table):\n",
    "            return (self._table[j]._key, self._table[j]._value)\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def find_range(self, start, stop):\n",
    "        \"\"\"Iterate all (key, value) pairs such that start <= key < stop.\n",
    "        \n",
    "        If start is None, iteration begins with minimum key of map.\n",
    "        If stop is None, iterations continues through the maximum key of map.\n",
    "        \"\"\"\n",
    "        if start is None:\n",
    "            j = 0\n",
    "        else:\n",
    "            j = self._find_index(start, 0, len(self._table)-1)       # find first result\n",
    "        while j < len(self._table) and (stop is None or self._table[j]._key < stop):\n",
    "            yield (self._table[j]._key, self._table[j]._value)\n",
    "            j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "<img style=\"float: left\" width=\"500\" alt=\"table-10.3\" src=\"https://user-images.githubusercontent.com/20944657/36974761-2f6bedf2-20bb-11e8-80af-13aef87124c4.png\">\n",
    "<div style=\"clear: both\"></div>\n",
    "\n",
    "이제 우리가 구현한 `SortedTableMap`의 성능을 분석해보자. sorted map ADT의 모든 메소드의 작동 시간 요약은 위의 표를 참고하면 된다. `__len__`과 `find_min`, `find_max` 메소드의 시간 복잡도가 $O(1)$인 것은 당연하고, 테이블의 key를 순회하는 것은 $O(n)$ 시간에 끝난다. 다양한 형태의 탐색이 시간 복잡도가 $O(logn)$인 것은 $n$개의 항목에 대해 바이너리 서치를 실시할 때의 시간 복잡도가 $O(n)$이기 때문이다. 이는 Section 4.2의 명제 4.2에서 보인 바 있다. 따라서 `__getitem__`, `find_lt`, `find_gt`, `find_le`, `find_ge`는 모두 `_find_index`를 호출한 뒤 인덱스를 조절하기 위해 상수 개수의 연산을 실시하므로 시간복잡도가 $O(logn)$이다. `find_range`의 분석은 조금 더 흥미로운데, 바이너리 서치를 이용해서 범위 내의 첫번째 항목을 찾고(만약 있다면), 범위의 끝에 도달할 때까지 루프를 돌리면서 각각의 항목에 대해 결과를 보고(report)하는 $O(1)$의 연산을 한다. 따라서 범위 내에 $s$개의 항목이 있다면 전체 작동 시간은 $O(s + logn)$이다.\n",
    "\n",
    "이렇게 효율적인 탐색 연산과는 대조적으로 sorted table을 위한 업데이트 연산은 꽤나 시간이 오래 걸린다. 바이너리 서치를 통해 추가나 삭제의 업데이트를 실행할 인덱스를 빠르게 찾을 수는 있지만, 최악의 경우 테이블의 순서를 유지하기 위해 선형적으로 많은 개수의 원소를 이동해야 하는 경우가 생긴다. 특히 `__setitem__`에서 `_table.insert`를 호출하거나 `__delitem__`에서 `_table.pop`을 호출하면 최악의 경우 $O(n)$ 시간이 걸린다(Section 5.4.1의 `list` 클래스에 대한 논의 참고).\n",
    "\n",
    "따라서, sorted table은 탐색이 많이 일어나지만 업데이트는 잘 일어나지 않는 경우에 주로 사용된다.\n",
    "\n",
    "### 10.3.2 Two Applications of Sorted Maps\n",
    "이번 섹션에서는 전통적인 (정렬이 되지 않은) 맵을 이용하기 보다 *정렬된* 맵을 이용하는 것이 이점을 갖는 예제를 살펴본다.key가 완전히 순서가 매겨지는(totally ordered) 도메인의 문제일 때만 sorted map을 적용하는 것이 가능하다. 또, sorted map에 의해 제공되는 부정확한(inexact) 탐색 혹은 범위(range) 탐색의 이점을 보기 위해서는 key가 가까운 것이 어떤 의미를 갖는 지 설명할 수 있어야 한다.\n",
    "\n",
    "### Flight Databases\n",
    "인터넷에는 사용자들이 여러 도시들 사이의 항공편을 사기 위해 항공 데이터베이스에 쿼리를 날리는 것을 허용하는 많은 웹 사이트들이 있다. 쿼리를 날리기 위해서 사용자는 출발 도시와 도착 도시, 출발 시간과 도착 시간을 지정해줘야 한다. 이러한 쿼리를 지원하기 위해 우리는 이러한 4개의 매개변수를 저장하는 `Flight` 객체를 key로 이용하는 맵을 이용해서 항공 데이터베이스를 만들 수 있다. 즉, key는 튜플 `k = (origin, destination, date, time)`이 된다. 또, 항공편 번호, 남은 좌석 수, 비행 시간, 운임 등의 추가적인 정보가 value 객체에 저장될 수도 있다.\n",
    "\n",
    "요청받은 항공편을 찾는 것은 단순히 요청받은 쿼리와 정확히 일치하는 것을 찾는 문제로 끝나지 않는다. 비록 사용자가 일반적으로 출발 도시와 도착 도시는 정확히 일치하기를 원하긴 하지만, 아마도 출발 일자나 출발 시간에 관해서는 조금 더 유연성을 갖고 있을 수 있다. 우리는 우리의 key들을 사전편찬식(lexicographic)으로 순서를 매김으로써 이러한 쿼리를 다룰 수 있다. 바로 이러한 이유로 sorted map을 이용한 효율적인 구현이 사용자들의 쿼리를 처리하기에 좋은 방법이 될 수 있다. 예를 들어, 사용자가 key $k$에 대한 쿼리를 날렸다고 하자. 우리는 `find_ge(k)`를 호출해서 출발과 도착 도시는 사용자의 쿼리와 일치하지만, 사용자가 날린 쿼리의 시간과 일치하거나 그 시간보다 늦은 출발 시간의 항공편을 반환하게끔 할 수 있다. 더 나은 방법은, key를 잘 설계해서, `find_range(k1, k2)`를 호출하면 주어진 범위의 시간 안에 있는 모든 항공편을 찾게끔 하는 것이다. 예를 들어 `k1 = (ORD, PVD, 05May, 09:30)`이고 `k2 = (ORD, PVD, 05May, 20:00)`일 때 `find_range(k1, k2)`를 호출하면 다음의 key-value 페어들이 반환되게끔 하는 것이 바람직하다:\n",
    "```\n",
    "(ORD, PVD, 05May, 09:53)   :   (AA 1840, F5, Y15, 02:05, $251)\n",
    "(ORD, PVD, 05May, 13:29)   :   (AA 600, F2, Y0, 02:16, $713)\n",
    "(ORD, PVD, 05May, 17:39)   :   (AA 416, F3, Y9, 02:09, $365)\n",
    "(ORD, PVD, 05May, 19:50)   :   (AA 1828, F9, Y25, 02:13, $186)\n",
    "```\n",
    "\n",
    "### Maxima Sets\n",
    "삶은 언제나 트레이드 오프로 가득하다. 가끔씩은 비용 절감을 위해 성능을 포기해야 하는 경우가 생긴다. 예를 들어 자동차를 그 최대 속도와 그 비용으로 점수를 매기는 데이터베이스를 만드는 것에 관심이 있다고 해보자. 우리는 어느 정도의 돈을 갖춘 사람이라면 우리의 데이터베이스에 쿼리를 날려서 살 수 있는 차 중에 가장 빠른 차를 찾을 수 있게끔 하고 싶다. 역시나 이런 경우에도 `(cost,speed)` 페어를 맵에 저장하는 모형을 만들어 이 trade-off 문제를 설명할 수 있다. \n",
    "이러한 문제에서는 어떤 차들은 항상 다른 차보다 좋다고 판단하는 것이 가능하다. 예를 들어 cost-speed 페어가 (20000,100)인 차는 (30000, 90)인 차보다 속도도 빠르면서 비용도 저렴하기 때문에 항상 좋다. 어떤 차가 확실히 더 낫다고 말할 수 없는 경우도 존재한다. 예를 들어 (20000,100)인 차는 (30000,120)인 차보다 비용은 저렴하지만 최대 속도는 낮기 때문에 우리가 얼마만큼의 비용을 쓸 수 있는가에 따라 좋을수도 나쁠수도 있다. \n",
    "\n",
    "<img width=\"400\" alt=\"figure-10.9\" src=\"https://user-images.githubusercontent.com/20944657/36979609-65d43cae-20cb-11e8-81bf-082dea45a880.png\">\n",
    "\n",
    "위의 그림에서 $p$는 항상 $c$,$d$,$e$보다 낫다. 그러나 우리의 지불 용의(willingness to pay)가 얼마인지에 따라 $p$는 $a$,$b$,$f$,$g$,$h$보다 좋을 수도 있고 나쁠 수도 있다. 따라서 만약 집합에 $p$를 추가한다면 $c$, $d$, $e$는 지울 수 있지만 다른 차들은 지울 수 없다.\n",
    "\n",
    "우리는 $a \\leq c$, $b \\geq d$일 때 비용-성능 페어 $(a,b)$가 $(c,d) \\neq (a,b)$를 **지배(dominate)**한다고 한다. 즉, 첫번째 페어의 비용이 더 낮거나 같으면서 성능은 더 좋거나 같을 때 첫번째 페어가 두번째 페어를 지배한다고 말할 수 있다. 페어 $(a,b)$는 다른 어떠한 페어에 의해서도 지배받지 않을 때 **최대(maximum)** 페어라고 한다. 우리는 비용-성능 페어의 집합 안에서도 최대 페어의 집합을 찾아 저장하는 데 관심이 있다. 즉, 우리는 새로운 차가 추가될 때마다 최대 페어가 되는지 판단해서 이 최대 페어 집합 안에 추가하고, 달러 $d$가 주어졌을 때 $d$보다 비용이 적게 들면서도 가장 빠른 차를 찾기 위해 이 최대 페어 집합에 쿼리를 날리는 것을 목표로 한다.\n",
    "\n",
    "### Maintaining a Maxima Set with a Sorted Map\n",
    "우리는 최대 페어의 집합을 sorted map $M$으로 저장해서 비용이 key이고 성능(속도)이 value이게끔 할 수 있다. 그러면 새로운 비용-성능 페어 (c,p)를 추가하는 연산 `add(c,p)`와, 비용이 최대 $c$일 때 가장 좋은 페어를 반환하는 `best(c)`를 정의하는 것이 다음과 같이 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CostPerformanceDatabase:\n",
    "    \"\"\"Maintain a database of maximal (cost, performance) pairs.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Create an empty database.\"\"\"\n",
    "        self._M = SortedTableMap()              # or a more efficient sorted map\n",
    "        \n",
    "    def best(self, c):\n",
    "        \"\"\"Return (cost, performance) pair with largest cost not exceeding c.\n",
    "        \n",
    "        Return None if there is no such pair.\n",
    "        \"\"\"\n",
    "        return self._M.find_le(c)\n",
    "    \n",
    "    def add(self, c, p):\n",
    "        \"Add new entry with cost c and performance p.\"\n",
    "        # determine if (c,p) is dominated by an existing pair\n",
    "        other = self._M.find_le(c)                 # other is at least as cheap as c\n",
    "        if other is not None and other[1] >= p:    # if its performance is as good,\n",
    "            return                                 # (c,p) is dominated, so ignore\n",
    "        self._M[c] = p                             # else, add (c,p) to database\n",
    "        # and now remove any pairs that are dominated by (c,p)\n",
    "        other = self._M.find_gt(c)                 # other more expensive than c\n",
    "        while other is not None and other[1] <= p:\n",
    "            del self._M[other[0]]\n",
    "            other = self._M.find_gt(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러나 불행히도 만약 `SortedTableMap`을 이용해서 $M$을 구현하게 되면 `add`가 $O(n)$ worst-case 작동 시간을 갖는다. 만약 스킵 리스트(skip list)를 이용해서 $M$을 구현할 경우 `best(c)` 쿼리를 $O(logn)$ 예측 시간 안에 날릴 수 있고, `add(c,p)` 업데이트를 $O((1+r)logn)$ 예측 시간 안에 실행할 수 있게 된다. 이 때 $r$은 제거하는 원소의 개수이다. 스킵 리스트는 바로 밑의 다음 세션에서 다룰 것이다.\n",
    "\n",
    "## 10.4 Skip Lists\n",
    "sorted map ADT를 구현하는 데 쓸 수 있는 흥미로운 자료 구조가 있는데, 바로 **스킵 리스트(skip list)**이다. 우리는 Section 10.3.1에서, 정렬된 배열에 대해서는 바이너리 서치 알고리즘을 이용해 $O(long)$ 시간 안에 탐색하는 것이 가능하다는 것을 살펴보았다. 불행히도 정렬된 배열에 대한 업데이트 연산은 원소의 위치를 바꿔줘야 하는 문제로 인해 최악의 경우 $O(n)$ 시간이 걸린다. Chapter 7에서 우리는 링크드 리스트를 이용하면, 리스트 안의 위치를 확인할 수만 있다면 업데이트 연산을 매우 빠르게 할 수 있다는 것을 설명했었다. 그러나 불행히도 표준적인 링크드 리스트에서는 빠른 탐색을 할 수가 없다. 예를 들어 바이너리 서치 알고리즘을 이용하기 위해서는 인덱스를 이용해 시퀀스의 원소를 직접 접근(access)할 수 있어야 한다.\n",
    "\n",
    "스킵 리스트는 효율적으로 탐색을 지원하면서도 업데이트 연산을 할 수 있게끔 현명하게 타협점을 찾은 사례이다. 맵 $M$에 대한 **스킵 리스트(skip list)** $S$는 리스트들의 열 ${S_{0}, S_{1}, ..., S_{h}}$로 구성된다. 각각의 리스트 $S_{i}$는 key에 대해 오름차순으로 정렬된 $M$의 항목들을 저장하면서도 두 센티널 key $+\\infty$와 $-\\infty$를 포함하고 있는데, $-\\infty$는 $M$에 추가될 수 있는 어떠한 key보다도 작고, $+\\infty$는 $M$에 추가될 수 있는 어떠한 key보다도 크다. 추가적으로, $S$ 안의 리스트는 다음의 성질을 만족한다:\n",
    "- 리스트 $S_{0}$은 맵 $M$의 모든 항목을 포함한다(센티널 $-\\infty$와 $+\\infty$ 포함).\n",
    "- $i = 1, ..., h-1$에 대해 리스트 $S_{i}$는 리스트 $S_{i-1}$의 항목에서 랜덤으로 생성된 부분집합을 포함한다(센티널 $-\\infty$와 $+\\infty$ 포함).\n",
    "- 리스트 $S_{h}$는 $-\\infty$와 $+\\infty$만 포함한다.\n",
    "\n",
    "스킵 리스트의 예제는 아래의 그림에 있다. 관례적으로 스킵리스트 $S$를 그림으로 나타날 때에는 $S_{0}$을 가장 아래에 두고, $S_{1}, ..., S_{h}$를 그 위에 둔다. 또한 우리는 $h$를 스킵 리스트 $S$의 **높이(height)**라고 한다.\n",
    "\n",
    "<img width=\"700\" alt=\"figure-10.10\" src=\"https://user-images.githubusercontent.com/20944657/36980972-3a56d9d4-20cf-11e8-8a97-bf18ebb499ad.png\">\n",
    "\n",
    "직관적으로, 리스트들은 $S_{i+1}$이 리스트 $S_{i}$보다 적거나 같은 항목을 포함하게끔 만들어진다. 뒤의 추가(insertion) 메소드에서 디테일을 보게 되겠지만, $S_{i+1}$의 항목들은 $S_{i}$에서 각각의 항목을 $1/2$의 확률로 뽑아서 결정된다. 즉, $S_{i}$의 각각의 원소들에 대해 \"동전을 던져서\" head가 나오면 $S_{i+1}$에 포함시키는 셈이다. 따라서 우리는 $S_{1}$이 $n/2$개의 항목을, $S_{2}$가 $n/4$개의 항목을 가질 것이라 기대하고, 일반적으로 $S_{i}$는 $n/2^{i}$ 항목을 가질 것으로 기대한다. 다시 말해서, 우리는 $S$의 높이 $h$가 $logn$ 정도가 될 것이라 기대한다. 그러나 리스트의 원소 수를 반으로 줄이는 것은 스킵 리스트의 명시적인 특성이 아니다. 대신에 랜덤 추출이 이용될 수 있다.\n",
    "\n",
    "랜덤한 숫자처럼 보이는 숫자들을 생성하는 함수는 컴퓨터 게임, 암호학, 컴퓨터 시뮬레이션 등 다양한 환경에서 널리 사용되고 있기 때문에 대부분의 현대 컴퓨터에서 구현되어 있다. **pseudo-random number generator**라 불리는 일부 함수들은 초기 **seed**부터 시작해서 랜덤처럼 보이는 숫자들을 생성하기도 한다. 어떤 메소드들은 하드웨어 장치를 이용해서 자연으로부터 \"진정한\" 랜덤 숫자를 추출해낸다. 어떤 방식을 이용하던 간에 우리는 우리의 컴퓨터가 분석을 위해 충분히 랜덤한 숫자들을 만들어낼 능력이 있다고 가정할 것이다.\n",
    "\n",
    "자료 구조와 알고리즘 설계에서 **랜덤화(randomization)**를 이용하는 것의 가장 큰 장점은 그 결과로 나오는 구조와 함수들이 주로 간단하고 효율적이게 된다는 점이다. 예를 들어, 스킵 리스트는 바이너리 서치 알고리즘과 같이 로그 시간 bound를 갖는 탐색을 할 수 있을 뿐 아니라 항목의 추가와 삭제와 같은 업데이트 메소드에 대해서도 좋은 성능을 얻는 것이 가능하다. 그러나 스킵 리스트의 bound는 **예상되는(expected)** 것이지만 바이너리 서치의 경우에는 **최악의 경우(worst-case)**의 bound라는 점에 유의해야 할 필요가 있다.\n",
    "\n",
    "스킵 리스트는 그 구조를 랜덤하게 결정하기 때문에 탐색과 업데이트를 위한 시간이 **평균적으로** $O(logn)$이 된다. 흥미롭게도 평균 시간 복잡도(average time complexity)의 개념은 입력된 key의 확률 분포에 의존하지 않는다. 대신에 평균 시간 복잡도는 새로운 항목을 어디에 추가해야 할 지 결정하는 것을 돕는 랜덤 넘버 제너레이터의 사용에 의존한다. 평균적인 작동 시간은 새 항목을 추가할 때 생성될 수 있는 모든 랜덤 숫자들에 대해 평균을 취해서 구해진다.\n",
    "\n",
    "리스트와 트리에서 사용했었던 위치 추상화를 이용하면, 우리는 스킵 리스트를 수평적으로는 **레벨**, 수직적으로는 **타워**로 구성되어 있는 위치의 2차원 집합으로 볼 수 있다. 각각의 레벨은 리스트 $S_{i}$이고, 각각의 타워는 연속적인 리스트에 걸쳐서 같은 항목을 저장하는 위치들을 포함한다. 스킵 리스트에서는 다음의 연산들을 통해 위치를 탐색할 수 있다:\n",
    "- **next(p):** $p$의 다음에 나오는(following) 같은 레벨의 위치를 반환한다.\n",
    "- **prev(p):** $p$의 이전에 나오는(preceding) 같은 레벨의 위치를 반환한다.\n",
    "- **below(p):** 같은 타워에서 $p$의 아래에 있는 위치를 반환한다.\n",
    "- **above(p):** 같은 타워에서 $p$의 위에 있는 위치를 반환한다.\n",
    "\n",
    "우리는 관례적으로 위의 연산에서 해당하는 위치가 존재하지 않으면 None을 반환한다고 가정한다. 디테일한 부분은 생략하고, 우리는 링크 구조를 이용해서 스킵 리스트를 구현하고 스킵 리스트의 위치 $p$가 주어졌을 때 개별적인 탐색 메소드가 $O(1)$ 시간이 걸리게 할 수 있다. 그러한 링크 구조는 본질적으로 타워에 정렬된 $h$개의 더블 링크드 리스트의 집합인데, 그 집합 또한 더블 링크드 리스트가 된다.\n",
    "\n",
    "### 10.4.1 Search and Update Operations in a Skip List\n",
    "스킵 리스트 구조는 간단한 맵 탐색과 업데이트 알고리즘을 제공한다. 스킵 리스트의 탐색과 업데이트 알고리즘은 모두 `SkipSearch` 메소드에 의존하는데, 이 `SkipSearch` 메소드는 key $k$를 받아서, $S_{0}$ 안에서 $k$보다 작거나 같은 key 중에 가장 큰 key를 찾아 그 위치를 반환한다. \n",
    "\n",
    "### Searching in a Skip List\n",
    "탐색하고자 하는 키 $k$가 주어졌다고 하자. `SkipSearch` 메소드가 가장 먼저 하는 일은 위치 변수 $p$를 스킵 리스트 $S$ 안에서도 가장 높으면서도 가장 왼쪽에 위치한 **시작 위치(start position)**로 설정하는 것이다. 즉, 시작 위치는 $S_{h}$ 안에서 key $-\\infty$를 저장하는 위치가 된다. `key(p)`가 $p$에 있는 항목의 key를 의미한다고 하자. 이제 우리는 다음의 과정을 따른다:\n",
    "1. 만약 `S.below(p)`가 None이면 탐색이 종료된다. 우리는 **바닥에 있고(at the bottom)**, $S$ 안에서 $k$보다 작거나 같은 key 중에서 가장 큰 key를 찾았다. 만약 None이 아니라면 우리는 현재 타워 안에서 `p = S.below(p)`를 실행하여 한단계 낮은 레벨로 **내려간다(drop down)**.\n",
    "2. 위치 $p$에서 시작해서 우리는 `key(p) <= k`가 유지되는 동안 같은 레벨에서 최대한 오른쪽으로 이동한다. 우리는 이를 **전방 스캔(scan forward)** 과정이라 부른다. 이 때 $-\\infty$와 $+\\infty$의 존재로 인해 이러한 성질을 만족하는 위치가 항상 존재한다는 점에 주의해야 한다. $p$가 전방 스캔을 시작하기 전과 여전히 같은 위치에 있을 수도 있다.\n",
    "3. 1로 돌아가서 반복한다.\n",
    "\n",
    "아래의 그림은 스킵 리스트에서 key 50을 찾는 과정을 그림으로 표현한 것이다.\n",
    "\n",
    "<img width=\"800\" alt=\"figure-10.11\" src=\"https://user-images.githubusercontent.com/20944657/36983138-f23d2198-20d4-11e8-8d77-750dc01efc6c.png\">\n",
    "\n",
    "스킵 리스트 서치 알고리즘의 pseudo-code는 다음과 같다.\n",
    "\n",
    "**Algorithm** SkipSearch(k):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Input:** A search key k<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Output:** Position p in the bottom list $S_{0}$ with the largest key such that key(p) $leq$ k<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;p = start<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**while** below(p) $\\neq$ **None** **do**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;p = below(p)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**while** k $\\geq$ key(next(p)) **do**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;p = next(p)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**return** p<br>\n",
    "\n",
    "이 메소드를 이용하면 `p = SkipSearch(k)`를 실행하고 `key(p) == k`를 테스트함으로써 맵 연산 `M[k]`를 실행할 수 있다. 만약 두 키가 같다면 연결된 값을 반환하고, 그렇지 않다면 KeyError가 발생한다. 위 `SkipSearch` 알고리즘의 예상 작동 시간은 $O(logn)$이지만, 이에 대한 증명은 스킵 리스트의 업데이트 메소드를 구현한 뒤로 미루자. `SkipSearch(k)`를 통해 얻게 되는 위치는 sorted map ADT의 여러 다른 형태의 탐색에서도 유용하게 이용할 수 있다.\n",
    "\n",
    "### Insertion in a Skip List\n",
    "맵 연산 `M[k] = v`를 실행하기 위해서도 우선 `SkipSearch(k)`를 실행해야 한다. 이를 통해 $k$보다 작거나 같으면서도 가장 큰 key를 가진 가장 아래 레벨의 위치 $p$를 얻을 수 있다($p$는 key $-\\infty$를 가질 수도 있다). 만약 key($p$) = $k$이면 연결된 값이 $v$로 대체된다. 그렇지 않다면 우리는 (k,v)를 위한 새로운 타워를 만들어야 한다. 이를 위해서는 $S_{0}$ 안에서 $p$ 뒤에 나오는 위치에 (k,v)를 추가하면 된다. 가장 아래 레벨에 새로운 항목을 추가한 후에는 randomization을 이용해서 새로운 항목의 타워의 높이를 결정해야 한다. 만약 동전을 던져서 tail이 나오면 그 즉시 멈춘다. 그렇지 않고 head가 나온 경우 한 층(레벨)을 올라가서 적절한 위치에 (k,v)를 추가한다. 또 동전을 던지고, head가 나오면 한 층 더 올라가고, 이를 계속해서 반복한다. 이렇게 해서 tail이 나올 때까지 쌓은 (k,v)들을 묶어서 하나의 타워로 만든다. 이렇게 동전을 던지는 과정은 파이썬의 built-in psuedo-random number generator인 `random.randrange()`를 이용해서 구현할 수 있다.\n",
    "\n",
    "스킵 리스트 $S$에 새로운 항목을 추가하는 insertion 알고리즘은 아래와 같다.\n",
    "\n",
    "**Algorithm** SkipInsert(k,v):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Input:** Key $k$ and value $v$<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Output:** Topmost position of the item inserted in the skip list<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;p = SkipSearch(k)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;q = **None**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;i = -1<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**repeat**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;i = i + 1<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**if** i $\\geq$ h **then**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;h = h + 1<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;t = next(s)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;s = insertAfterAbove(None, s, ($-\\infty$, **None**))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;insertAfterAbove(s, t, ($+\\infty$, **None**))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**while** above(p) is **None do**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;p = prev(p)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;p = above(p)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;q = insertAfterAbove(p, q, (k, v))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**until** coinFlip() == tails<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;n = n + 1<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**return** q<br>\n",
    "\n",
    "<img width=\"800\" alt=\"figure-10.12\" src=\"https://user-images.githubusercontent.com/20944657/37010047-f32d069c-212c-11e8-9ed5-b5462c25ef22.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 나머지 내용은 아래의 코드로 대체..\n",
    "개인적으로 위의 알고리즘부터 10.4의 스킵 리스트가 잘 이해가 안되어서 [이 블로그](https://kunigami.blog/2012/09/25/skip-lists-in-python/)를 참조하여 \n",
    "간단하게 스킵 리스트를 파이썬으로 구현해보았고, 이로써 나머지 섹션의 내용을 대체하고, 바로 스킵 리스트의 효율성 분석으로 넘어간다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SkipNode:\n",
    "    def __init__(self, height = 0, elem = None):\n",
    "        self.elem = elem\n",
    "        self.next = [None]*height\n",
    "        \n",
    "class SkipList:\n",
    "    def __init__(self):\n",
    "        self.head = SkipNode()\n",
    "        self.len = 0\n",
    "        self.maxHeight = 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def contains(self, elem, update = None):\n",
    "        return self.find(elem, update) != None\n",
    "        \n",
    "    def randomHeight(self):\n",
    "        height = 1\n",
    "        while randint(1,2) != 1:\n",
    "            height += 1\n",
    "        return height\n",
    "    \n",
    "    def updateList(self, elem):        \n",
    "        update = [None] * len(self.head.next)\n",
    "        x = self.head\n",
    "        \n",
    "        for i in reversed(range(len(self.head.next))):\n",
    "            while x.next[i] != None and x.next[i].elem < elem:  # find the largest element\n",
    "                x = x.next[i]                                   # that is smaller than q\n",
    "            update[i] = x                                       # insert this node to update list\n",
    "        \n",
    "        return update\n",
    "    \n",
    "    def find(self, elem, update = None):\n",
    "        if update == None:\n",
    "            update = self.updateList(elem)\n",
    "        if len(update) > 0:\n",
    "            candidate = update[0].next[0]\n",
    "            if candidate != None and candidate.elem == elem:\n",
    "                return candidate\n",
    "        return None\n",
    "    \n",
    "    def insert(self, elem):\n",
    "        node = SkipNode(self.randomHeight(), elem)\n",
    "        while len(self.head.next) < len(node.next):   # if new node's height is higher than header's\n",
    "            self.head.next.append(None)               # grow header's height\n",
    "            \n",
    "        update = self.updateList(elem)\n",
    "        if self.find(elem, update) == None:\n",
    "            for i in range(len(node.next)):\n",
    "                node.next[i] = update[i].next[i]      # new node's next node is update node's next node.\n",
    "                update[i].next[i] = node              # link update node to new node\n",
    "            self.len += 1\n",
    "                \n",
    "    def remove(self, elem):\n",
    "        update = self.updateList(elem)\n",
    "        x = self.find(elem, update)\n",
    "        if x != None:\n",
    "            for i in range(len(x.next)):\n",
    "                update[i].next[i] = x.next[i]\n",
    "                if self.head.next[i] == None:\n",
    "                    self.maxHeight -= 1\n",
    "            self.len -= 1\n",
    "    \n",
    "    def printList(self):\n",
    "        for i in range(len(self.head.next)-1, -1, -1):\n",
    "            x = self.head\n",
    "            while x.next[i] != None:\n",
    "                print(x.next[i].elem)\n",
    "                x = x.next[i]\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.2 Probabilistic Analysis of Skip Lists\n",
    "앞서 봤듯이, 스킵 리스트는 sorted map의 간단한 구현을 제공한다. 그러나 worst-case 성능으로 볼 때 스킵 리스트는 딱히 좋은 자료 구조라 할 수 없다. 실제로, 만약 insertion의 과정에서 현재의 최고 레벨보다 더 레벨이 높아지는 것을 막지 않는다면 insertion 알고리즘은 거의 무한 루프에 가깝게 돌아갈 수도 있다(사실 계속해서 head가 나올 확률은 0에 가까우므로 무한 루프는 아니다). 그리고 메모리의 문제로 인해 계속해서 리스트에 위치를 추가할 수도 없다. 만약 우리가 최고 레벨 $h$에서 position insertion을 중단시킨다면, $n$개의 항목을 갖는 스킵 리스트 $S$에서 `__getitem__`, `__setitem__`, `__delitem__` 맵 연산을 실행하기 위한 **worst-case** 작동 시간은 $O(n+h)$가 된다. 그런데 이 worst-case 성능은 모든 항목의 타워의 레벨이 $h-1$일 때의 성능이다. 이런 사건이 일어날 확률은 굉장히 낮다. worst-case만 보고 판단하면 스킵 리스트 구조가 이번 챕터에서 다뤘던 다른 맵 구현보다 성능이 떨어진다고 할 수 있겠지만, worst-case만 보고 판단하는 것은 공정하지 않다.\n",
    "\n",
    "### Bounding the Height of a Skip List\n",
    "insertion의 과정에서 randomization이 일어나기 때문에 스킵 리스트를 더 엄밀하게 분석하기 위해서는 확률의 개념이 필요하다. 확률이라 하면 어렵게 느낄 수도 있지만, 운이 좋게도 분석을 위해서 스킵 리스트의 예상되는 동작을 모두 이해할 필요는 없다. 간단한 확률의 개념만 있어도 스킵 리스트의 확률론적 분석이 가능하다.\n",
    "\n",
    "이제 $n$개의 항목을 갖는 스킵 리스트 $S$의 예상되는 높이 $h$를 구해보자. 주어진 항목이 높이가 $i$인 타워를 가질 확률은 동전을 던졌을때 연속적으로 $i$개의 head가 나올 확률과 같다. 이 확률은 $1/2^{i}$이다. 따라서 레벨 $i$가 적어도 하나 이상의 위치를 가질 확률 $P_{i]}$은 $P_{i} \\leq \\dfrac{n}{2^{i}}$이다. 이 확률을 구하는 데에는 $n$개의 서로 다른 사건 중 하나라도 일어날 확률은 각각이 일어날 확률의 합 이하라는 사실이 이용되었다.\n",
    "\n",
    "이제 $S$의 높이 $h$가 $i$보다 클 확률은 레벨 $i$가 적어도 하나의 위치를 가질 확률과 같다. 그러면 예를 들어, $h$가 $3logn$보다 클 가능성은 최대 \n",
    "\n",
    "$P_{3logn} \\leq \\dfrac{n}{2^{3logn}} = \\dfrac{n}{n^{3}} = \\dfrac{1}{n^{2}}$ 이고, 만약 $n = 1000$이면 이 확률은 1/1,000,000이 된다. 일반적으로 상수 $c > 1$이 주어졌을 때, $h$가 $clog(n)$보다 작을 확률은 최소한 $1 - 1/n^{c-1}$이다. 따라서 매우 높은 확률로 $h$의 높이는 $O(logn)$ 이다.\n",
    "\n",
    "### Analyzing Search Time in a Skip List\n",
    "이제 스킵 리스트 $S$의 탐색 작동 시간을 살펴보자. 이러한 탐색 과정은 두개의 중첩된 **while** 루프를 이용한다. 내부의(inner) 루프는 다음 key가 탐색 key $k$보다 크지 않다면 $S$의 레벨 안에서 전방으로 스캔을 실시한다. 외부(outer) 루프는 다음 레벨로 내려간 후 전방 탐색 iteration을 반복한다. $h$의 높이가 높은 확률로 $O(logn)$이므로 높은 확률로 drop-down 스텝의 수는 $O(logn)$이 된다. \n",
    "\n",
    "그런데 우리는 아직 전방 스캔의 수를 제한하지는 않았다. $n_{i}$를 레벨 $i$에서 전방 스캔하는 도중 만나는 key의 숫자로 두자. 그러면 이제 레벨 $i+1$에서는 레벨 $i$에서 만나지 않았던 추가적인 key를 만나게 된다. 만약 이전 레벨에 키가 있었다면 이미 이전 단계의 전방 탐색에서 그 키들을 만났을 것이므로, 임의의 키가 $n_{i}$에서 카운트 될 확률은 $1/2$이다 따라서 $n_{i}$의 예측 값은 공정한 코인을 던져서 head가 나올 때까지의 예상되는 갯수와 동일하다. 이 값은 2이다. 따라서 임의의 레벨 $i$에서의 예상 전방 탐색 시간은 $O(1)$이 된다. $S$의 레벨 수가 높은 확률로 $O(logn)$이므로 $S$의 탐색 예상 시간은 $O(logn)$이다. 비슷한 분석을 통해 추가나 삭제도 $O(logn)$ 예상 시간 복잡도를 갖는 것을 보일 수 있다.\n",
    "\n",
    "### Space Usage in a Skip List\n",
    "마지막으로, $n$개의 항목을 갖는 스킵 리스트 $S$의 공간 복잡도를 알아보자. 위에서 봤듯이 레벨 $i$의 예상되는 위치의 개수는 $n/2^{i}$이고, 이는 $S$의 예상되는 총 위치 개수는 $\\sum_{i=0}^{h} \\dfrac{n}{2^{i}} = n \\sum^{h}_{i=0} \\dfrac{1}{2^{i}}$이 된다. 이때 $\\sum_{i=0}^{h} \\dfrac{1}{2^{i}} = \\dfrac{(\\frac{1}{2})^{h+1} - 1}{\\frac{1}{2} - 1} = 2 \\cdot (1 - \\dfrac{1}{2^{h+1}}) \\lt 2$ for all $h \\geq 0$이므로, $S$의 예상 공간 복잡도는 $O(n)$이다. 아래는 이상의 논의를 종합한 것이다.\n",
    "\n",
    "<img width=\"600\" alt=\"table-10.4\" src=\"https://user-images.githubusercontent.com/20944657/37014307-1879490e-2143-11e8-9a3e-918b4da7a86d.png\">\n",
    "\n",
    "## 10.5 Sets, Multisets, and Multimaps\n",
    "맵 ADT와 밀접하게 관련된 몇몇 추가적인 추상화를 다루면서 이 챕터를 마치자.\n",
    "- **set**은 순서가 없는 원소들의 집합이다. 이 때 집합에는 중복되는 원소가 없고, 효율적인 멤버쉽 테스트를 제공한다. 본질적으로 집합의 원소들은 value를 갖지 않는 key와 비슷하다.\n",
    "- **multiset**(**bag**이라고도 알려진)은 중복되는 원소를 허용하는 set과 유사한 컨테이너이다.\n",
    "- **multimap**은 key를 value와 연결한다는 점에서 전통적인 맵과 유사하지만, 멀티맵에서는 동일한 키가 다양한 value로 매핑될 수 있다.\n",
    "\n",
    "### 10.5.1 The Set ADT\n",
    "파이썬은 built-in 클래스인 **frozenset**과 **set**을 이용해서 set의 수학적인 개념을 표현한다. set과 frozenset의 차이는 frozenset이 immutable하다는 것이다. 이 두 클래스는 모두 파이썬의 해쉬 테이블을 이용해서 구현됐다. 파이썬의 `collections` 모듈은 이러한 built-in 클래스를 따라하는 추상 기초 클래스를 정의한다. 그 이름은 굉장히 직관적이지 않지만, `collections.Set` 추상 기초 클래스는 `frozenset` 클래스와 매치되고, `collections.MutableSet`은 `set` 클래스와 매치된다. 우리의 논의에서 우리는 \"set ADT\"를 built-in `set` 클래스의 동작과 일치하게끔 할 것이다(`collections.MutableSet` 기초 클래스와도 일치). 우선 set $S$에서 가장 중요하다고 여겨지는 5개의 핵심 동작을 살펴보자:\n",
    "- **S.add(e):** 원소 $e$를 set에 추가한다. 만약 set이 이미 $e$를 포함하고 있다면 이 메소드는 효과가 없다.\n",
    "- **S.discard(e):** set 안에 원소 $e$가 있다면 원소 $e$를 제거한다. 만약 set 안에 $e$가 없다면 이 메소드는 효과가 없다.\n",
    "- **e in S:** 만약 set이 $e$를 포함한다면 True를 반환한다. 파이썬에서 이 메소드는 `__contains__` 스페셜 메소드를 통해 구현된다.\n",
    "- **len(S):** set $S$의 원소의 개수를 반환한다. 파이썬에서 이 메소드는 `__len__` 스페셜 메소드를 통해 구현된다.\n",
    "- **iter(S):** set 안의 모든 원소에 대한 iteration을 생성한다. 파이썬에서 이 메소드는 `__iter__` 스페셜 메소드를 통해 구현된다.\n",
    "\n",
    "다음 섹션에서 우리는 위의 다섯가지 메소드만 갖고도 set의 다른 모든 동작을 도출하는 것이 가능하다는 것을 보일 것이다. 남은 동작들은 다음과 같이 묶일 수 있다. 우선 set에서 하나 이상의 원소를 제거하는 추가적인 연산부터 보자.\n",
    "- **S.remove(e):** set에서 원소 $e$를 제거한다. 만약 set이 $e$를 포함하지 않는다면 `KeyError`가 발생한다.\n",
    "- **S.pop():** set에서 임의의 원소를 제거하고 반환한다. 만약 set이 비어있다면 `KeyError`가 발생한다.\n",
    "- **S.clear():** set에서 모든 원소를 제거한다.\n",
    "\n",
    "다음에 설명할 동작들은 두 set 사이의 Boolean 비교를 실시한다.\n",
    "- **S == T:** $S$와 $T$가 동일한 내용물을 가질 경우 True를 반환한다.\n",
    "- **S != T:** $S$와 $T$가 동일하지 않으면 True를 반환한다.\n",
    "- **S <= T:** $S$가 $T$의 부분집합이면 True를 반환한다.\n",
    "- **S < T:** $S$가 $T$의 진부분집합(proper subset)이면 True를 반환한다.\n",
    "- **S >= T:** $T$가 $S$의 부분집합이면 True를 반환한다.\n",
    "- **S > T:** $T$가 $S$의 진부분집합이면 True를 반환한다.\n",
    "- **S.isdisjoint(T):** $S$와 $T$가 공통 원소를 가지 않으면 True를 반환한다.\n",
    "\n",
    "마지막으로, 이미 존재하는 set을 업데이트하거나 고전적인 set 이론 연산에 따라 새로운 set 인스턴스를 계산하는 다양한 동작들이 있다.\n",
    "\n",
    "- **S | T:** $S$와 $T$의 합집합인 새로운 set을 반환한다.\n",
    "- **S |= T:** $S$를 $S$와 $T$의 합집합으로 업데이트한다.\n",
    "- **S & T:** $S$와 $T$의 교집합인 새로운 set을 반환한다.\n",
    "- **S &= T:** $S$를 $S$와 $T$의 교집합으로 업데이트한다.\n",
    "- **S ^ T:** $S$와 $T$의 symmetric difference인 새로운 set을 반환한다. 즉, 이 새로운 set의 원소는 $S$나 $T$ 둘 중 하나에만 속하는 원소이다.\n",
    "- **S ^= T:** $S$를 $S$와 $T$의 symmetric difference로 업데이트한다.\n",
    "- **S - T:** $S$에 속하지만 $T$에 속하지 않는 새로운 set을 반환한다.\n",
    "- **S -= T:** $S$를 $S$에 속하지만 $T$에 속하지 않는 새로운 set으로 업데이트한다.\n",
    "\n",
    "### 10.5.2 Python's MutableSet Abstract Base Class\n",
    "유저 정의 set 클래스의 생성을 돕기 위해 파이썬의 `collections` 모듈은 `MutableSet` 추상 기초 클래스를 제공한다(Section 10.1.3에서 `MutableMapping`을 이용했던 것과 비슷하다). `MutableSet` 기초 클래스는 다섯개의 코어 동작(`add`, `discard`, `__contains__`, `__len__`, `__iter__`)을 제외한 나머지 모든 메소드에 대한 구상 메소드를 제공한다. 5개의 코어 동작은 추상 메소드로서 서브 클래스에서 구현되어야 한다. 이러한 디자인은 앞서 봤듯이 **템플릿 메소드 패턴**의 예제라 할 수 있다.\n",
    "\n",
    " 설명을 위해 `MutableSet` 기초 클래스의 메소드를 구현하기 위한 몇몇 알고리즘을 살펴보자. 예를 들어 하나의 set이 다른 set의 진부분집합인지 알기 위해서는 두 조건을 확인해야 한다: 진부분집합은 그 superset보다 크기가 작아야 하고, 이 부분집합의 원소는 반드시 superset에 포함되어야 한다. 이러한 논리를 바탕으로 구현한 `__lt__`의 코드는 다음과 같다.\n",
    " ```python\n",
    " def __lt__(self, other):      # supports syntax S < T\n",
    "     \"\"\"Return true if this set is a proper subset of other.\"\"\"\n",
    "     if len(self) >= len(other):\n",
    "         return False          # proper subset must have strictly smaller size\n",
    "     for e in self:\n",
    "         if e not in other:\n",
    "             return False      # not a subset since element missing from other\n",
    "     return True               # success; all conditions are met\n",
    " ```\n",
    " \n",
    " 또 다른 예제로서 두 set의 합집합을 구하는 계산을 살펴보자. set ADT는 합집합을 계산하기 위한 두 개의 형태를 갖는데, `S|T`는 새로운 합집합을 만드는 것이고, `S|=T`는 $S$를 합집합으로 업데이트하는 것이다. 굳이 두번째의 \"in-place\" 업데이트 메소드를 정의하는 이유는 이렇게 업데이트를 하는 것이 `S = S|T`를 통해 새로운 인스턴스를 만들고 이를 다시 $S$에 할당하는 것보다 효율적이기 때문이다. 편의를 위해 파이썬 built-in set 클래스는 이러한 동작들을 기호가 아닌 이름으로 실행할 수 있게끔 `S|T`와 동일한 `S.union(T)`, `S|=T`와 동일한 `S.update(T)`를 지원한다. 이는 `MutableSet` 추상 기초 클래스에서 지원하는 것은 아니다.\n",
    " \n",
    " ```python\n",
    " def __or__(self, other):\n",
    "     \"\"\"Return a new set that is the union of two exsiting sets.\"\"\"\n",
    "     result = type(self)()\n",
    "     for e in self:\n",
    "         result.add(e)\n",
    "     for e in other:\n",
    "         result.add(e)\n",
    "     return result\n",
    "```\n",
    "\n",
    "이 때 위의 코드에서 주목해야 할 부분은 `type(self)()`를 통해 새로운 set 인스턴스를 만드는 부분이다. `MutableSet` 클래스는 추상 기초 클래스이기 때문에 인스턴스를 만들 수 없고, 인스턴스는 구상 서브 클래스에 속해야 한다. 두 인스턴스의 합집합을 구할 때는 같은 클래스의 새로운 인스턴스를 만들어야 하는데, `type(self)` 코드는 `self`가 가리키는 인스턴스의 클래스에 대한 참조를 반환한다. 따라서 `type(self)()`는 그 클래스의 생성자(constructor)를 호출하게 될 것이다.\n",
    "\n",
    "효율성의 관점에서 볼 때, $S$의 크기를 $n$, $T$의 크기를 $m$이라 할 때 위 `__or__` 연산은 $S$와 $T$에 루프를 돌게 되므로 시간 복잡도가 $O(m+n)$이다. 만약 `S|=T` inplace 메소드에 대한 스페셜 메소드 `__ior__`를 아래와 같이 구현하면 새로운 인스턴스를 만들지 않고 이미 존재하는 set을 수정하기에 예상되는 작동 시간이 $O(m)$이 된다.\n",
    "\n",
    "```python\n",
    "def __ior__(self, other):     # supports syntax S|=T\n",
    "    \"\"\"Modify this set to be the union of itself an another set.\"\"\"\n",
    "    for e in other:\n",
    "        self.add(e)\n",
    "    return self               # technical requirement of in-place operator\n",
    "```\n",
    "\n",
    "### 10.5.3 Implementing Sets, Multisets, and Multimaps\n",
    "\n",
    "### Sets\n",
    "집합(set)과 맵은 매우 다른 퍼블릭 인터페이스를 갖고 있지만 꽤나 비슷하다. set은 맵에서 key가 연결된 value를 갖지 않는 특별한 경우라 할 수 있다. 맵을 구현하기 위해 이용된 모든 자료구조는 비슷한 성능을 가지면서 set을 구현하는 데 이용하는 것도 가능하다. 정말 단순하게 set을 구현하기 위해서는 맵의 구현에서 value를 모두 None 값으로 두고 key를 set의 원소로 두면 된다. 그러나 이는 쓸데없이 메모리를 낭비하는 일이다. 효율적인 set의 구현은 `MapBase` 클래스에서 이용했던 `_Item` 컴포지트를 버리고 자료 구조 안에 바로 set의 원소를 저장해야 한다.\n",
    "\n",
    "### Multisets\n",
    "multiset에서는 같은 원소가 여러번 등장할 수 있다. 지금까지 봤던 모든 자료구조가 중복된 원소를 서로 다른 원소로 구분하게끔 다시 구현될 수 있다. 그러나 multiset을 구현하는 또 다른 방법은 *맵*을 이용해서 맵의 key는 multiset의 원소로 두고 그 value를 multiset 안의 그 원소의 수로 두는 방법이다. 사실 이 방법은 우리가 Section 10.1.2에서 문서 내 단어의 빈도를 계산할 때 썼던 바로 그 방법이다.\n",
    "\n",
    "파이썬의 표준 `collections` 모듈은 `Counter`라는 이름으로 multiset을 제공한다. `Counter` 클래스는 `dict` 클래스의 서브클래스인데, 그 value가 정수일 것을 기대하고, $n$개의 가장 흔한 원소 리스트를 제공하는 `most_common(n)`과 같은 메소드를 지원한다. 표준적인 `__iter__` 메소드는 각각의 원소를 한번씩만 보고한다(형식적으로 볼 때 이 원소들은 딕셔너리의 key이기 때문이다). `Counter` 클래스는 `elements()`라는 이름의 메소드를 지원하는데, 이 메소드는 그 카운트의 수에 따라 원소를 반복해서 보고하며 multiset을 순회한다.\n",
    "\n",
    "### Multimaps\n",
    "파이썬의 표준 라이브러리에는 multimap이 없지만 흔히 구현하는 방법은 표준적인 map을 이용하되, key와 연결된 value가 그 key와 연결된 value들을 저장하는 컨테이너 클래스이게끔 하는 방법이다. 아래는 파이썬의 표준적인 `dict` 클래스를 이용해서 `MultiMap` 클래스를 구현한 코드이다. 여기서 만약 `dict`가 아닌 다른 맵 구현을 이용하고 싶다면 line 3의 `_MapType` attribute를 덮어쓰면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultiMap:\n",
    "    \"\"\"A multimap class built upon use of an underlying map for storage.\"\"\"\n",
    "    _MapType = dict                  # Map type; can be redefined by subclass\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Create a new empty multimap instance.\"\"\"\n",
    "        self._map = self._MapType()\n",
    "        self._n = 0\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Iterate through all (k,v) pairs in multimap.\"\"\"\n",
    "        for k, secondary in self._map.items():\n",
    "            for v in secondary:\n",
    "                yield (k,v)\n",
    "    \n",
    "    def add(self, k, v):\n",
    "        \"\"\"Add pair (k,v) to multimap.\"\"\"\n",
    "        container = self._map.setdefault(k, [])    # create empty list, if needed.\n",
    "        container.append(v)\n",
    "        self._n += 1\n",
    "        \n",
    "    def pop(self, k):\n",
    "        \"\"\"Remove and return arbitrary (k,v) with key k (or raise KeyError).\"\"\"\n",
    "        secondary = self._map[k]                    # may raise KeyError\n",
    "        v = secondary.pop()\n",
    "        if len(secondary) == 0:\n",
    "            del self._map[k]                        # no pairs left\n",
    "        self._n -= 1\n",
    "        return (k,v)\n",
    "    \n",
    "    def find(self, k):\n",
    "        \"\"\"Return arbitrary (k,v) pairs with given key.\"\"\"\n",
    "        secondary = self._map[k]      # may raise KeyError\n",
    "        return (k, secondary[0])\n",
    "            \n",
    "    def find_all(self, k):\n",
    "        \"\"\"Generate iteration of all (k,v) pairs with given key.\"\"\"\n",
    "        secondary = self._map.get(k, [])\n",
    "        for v in secondary:\n",
    "            yield (k,v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
